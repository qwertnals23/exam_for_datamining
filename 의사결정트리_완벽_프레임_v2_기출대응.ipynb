{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 의사결정트리 완벽 프레임 v2 - 시험용 🌳\n",
    "## 모든 기출 유형 대응! (F1 Score, ROC AUC, Accuracy 모두 포함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 필수 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# dmba 라이브러리 (있으면)\n",
    "try:\n",
    "    from dmba import classificationSummary\n",
    "    HAS_DMBA = True\n",
    "except:\n",
    "    HAS_DMBA = False\n",
    "    print(\"dmba 라이브러리가 없습니다. 기본 지표만 사용합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 로드 및 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 (⭐ 파일명 수정 필수!)\n",
    "df = pd.read_csv('데이터파일.csv')\n",
    "\n",
    "print(\"[데이터 정보]\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n[결측치 확인]\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n[데이터 샘플]\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 타입 자동 분류\n",
    "print(\"[변수 타입 분류]\")\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"범주형 변수 ({len(categorical_cols)}개): {categorical_cols}\")\n",
    "print(f\"수치형 변수 ({len(numerical_cols)}개): {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 제거 (기출에서 자주 요구)\n",
    "print(f\"결측치 제거 전: {df.shape}\")\n",
    "df = df.dropna()\n",
    "print(f\"결측치 제거 후: {df.shape}\")\n",
    "\n",
    "# 목표변수를 범주형으로 변환 (필요시)\n",
    "# df['목표변수'] = df['목표변수'].astype('category')\n",
    "\n",
    "# 독립변수/종속변수 분리 (⭐ 여기 수정 필수!)\n",
    "outcome = '목표변수'  # ← 종속변수 이름 입력\n",
    "predictors = [col for col in df.columns \n",
    "              if col not in [outcome, '제외할변수1', '제외할변수2']]\n",
    "\n",
    "X = df[predictors]\n",
    "y = df[outcome]\n",
    "\n",
    "# 원-핫 인코딩 (의사결정트리는 drop_first=False 가능)\n",
    "X = pd.get_dummies(X, drop_first=False)\n",
    "\n",
    "print(f\"\\n독립변수 개수: {X.shape[1]}\")\n",
    "print(f\"데이터 크기: {X.shape}\")\n",
    "print(f\"변수 목록 (처음 10개): {X.columns.tolist()[:10]}\")\n",
    "print(f\"\\n목표변수 분포:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 1: train_test_split 사용 (일반적)\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"학습 데이터: {train_X.shape}\")\n",
    "print(f\"검증 데이터: {valid_X.shape}\")\n",
    "print(f\"\\n학습 데이터 클래스 분포:\\n{train_y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 2: 인덱스 기반 분리 (기출문제 스타일)\n",
    "# 예: \"0~1999번까지 학습, 2000번~ 테스트\"\n",
    "\n",
    "# train_X = X.iloc[:2000]\n",
    "# train_y = y.iloc[:2000]\n",
    "# valid_X = X.iloc[2000:]\n",
    "# valid_y = y.iloc[2000:]\n",
    "\n",
    "# print(f\"학습 데이터: {train_X.shape}\")\n",
    "# print(f\"검증 데이터: {valid_X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 평가 함수 정의 (⭐ 기출 대응!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred, y_pred_proba=None, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    분류 모델 평가 - 모든 기출 지표 포함!\n",
    "    \n",
    "    기출 지표:\n",
    "    - Accuracy: 2021년\n",
    "    - F1 Score: 2022년, 2024년\n",
    "    - ROC AUC: 2021년, 2022년, 2023년\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # 이진 분류 vs 다중 분류\n",
    "    if len(np.unique(y_true)) == 2:\n",
    "        # 이진 분류\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"📊 {model_name} 성과 (이진 분류)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Accuracy:  {acc:.4f}  ← 2021년 기출\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}  ← 2022, 2024년 기출\")\n",
    "        \n",
    "        if y_pred_proba is not None:\n",
    "            auc = roc_auc_score(y_true, y_pred_proba)\n",
    "            print(f\"ROC AUC:   {auc:.4f}  ← 2021, 2022, 2023년 기출\")\n",
    "        print(f\"{'='*60}\")\n",
    "    else:\n",
    "        # 다중 분류\n",
    "        precision = precision_score(y_true, y_pred, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"📊 {model_name} 성과 (다중 분류)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"Precision (weighted): {precision:.4f}\")\n",
    "        print(f\"Recall (weighted):    {recall:.4f}\")\n",
    "        print(f\"F1 Score (weighted):  {f1:.4f}\")\n",
    "        print(f\"{'='*60}\")\n",
    "    \n",
    "    return {'Accuracy': acc, 'Precision': precision, 'Recall': recall, 'F1': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Decision Tree - 기본 모델 (Full Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"🌳 Decision Tree - 기본 모델 (제약 없음)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 모델 생성 (criterion은 'gini' 또는 'entropy')\n",
    "tree_full = DecisionTreeClassifier(criterion='entropy', random_state=1)\n",
    "tree_full.fit(train_X, train_y)\n",
    "\n",
    "# 예측\n",
    "pred_train_y = tree_full.predict(train_X)\n",
    "pred_valid_y = tree_full.predict(valid_X)\n",
    "\n",
    "# 확률 예측 (ROC AUC용)\n",
    "if len(np.unique(y)) == 2:\n",
    "    pred_valid_proba = tree_full.predict_proba(valid_X)[:, 1]\n",
    "else:\n",
    "    pred_valid_proba = None\n",
    "\n",
    "# 성과 측정\n",
    "print(\"\\n[학습 데이터 성과]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(train_y, pred_train_y, class_names=tree_full.classes_)\n",
    "else:\n",
    "    evaluate_classification(train_y, pred_train_y, model_name=\"Full Tree - Train\")\n",
    "\n",
    "print(\"\\n[검증 데이터 성과]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(valid_y, pred_valid_y, class_names=tree_full.classes_)\n",
    "else:\n",
    "    evaluate_classification(valid_y, pred_valid_y, pred_valid_proba, \"Full Tree - Valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나무 구조 정보\n",
    "print(\"\\n[나무 구조 정보]\")\n",
    "print(f\"최대 깊이: {tree_full.get_depth()}\")\n",
    "print(f\"리프 노드 수: {tree_full.get_n_leaves()}\")\n",
    "print(f\"총 노드 수: {tree_full.tree_.node_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 기출 대응: 다양한 평가 지표로 교차검증\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 5-Fold 교차검증 (다양한 평가 지표)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Accuracy\n",
    "scores_acc = cross_val_score(tree_full, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"\\n✅ 5-Fold CV Accuracy: {scores_acc.mean():.4f} (±{scores_acc.std():.4f})\")\n",
    "\n",
    "# F1 Score\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_f1 = cross_val_score(tree_full, X, y, cv=5, scoring='f1')\n",
    "    print(f\"✅ 5-Fold CV F1 Score: {scores_f1.mean():.4f} (±{scores_f1.std():.4f})\")\n",
    "else:\n",
    "    scores_f1 = cross_val_score(tree_full, X, y, cv=5, scoring='f1_weighted')\n",
    "    print(f\"✅ 5-Fold CV F1 Score (weighted): {scores_f1.mean():.4f} (±{scores_f1.std():.4f})\")\n",
    "\n",
    "# ROC AUC (이진 분류인 경우)\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_auc = cross_val_score(tree_full, X, y, cv=5, scoring='roc_auc')\n",
    "    print(f\"✅ 5-Fold CV ROC AUC: {scores_auc.mean():.4f} (±{scores_auc.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 변수 중요도 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame으로 정리\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': tree_full.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n[변수 중요도 Top 10]\")\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = importance_df.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.title('Top 15 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. max_depth 튜닝 및 시각화 ⭐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기출에서 자주 쓰는 평가 지표 선택\n",
    "if len(np.unique(y)) == 2:\n",
    "    scoring = 'roc_auc'  # 이진 분류: ROC AUC (2021, 2022, 2023)\n",
    "    metric_name = 'ROC AUC'\n",
    "else:\n",
    "    scoring = 'accuracy'  # 다중 분류: Accuracy\n",
    "    metric_name = 'Accuracy'\n",
    "\n",
    "print(f\"\\n평가 지표: {metric_name}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = range(2, 21)\n",
    "train_scores = []\n",
    "valid_scores = []\n",
    "cv_scores = []\n",
    "\n",
    "for depth in depths:\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, criterion='entropy', random_state=1)\n",
    "    tree.fit(train_X, train_y)\n",
    "    \n",
    "    # 학습 데이터 점수\n",
    "    if scoring == 'roc_auc':\n",
    "        train_pred_prob = tree.predict_proba(train_X)[:, 1]\n",
    "        valid_pred_prob = tree.predict_proba(valid_X)[:, 1]\n",
    "        train_scores.append(roc_auc_score(train_y, train_pred_prob))\n",
    "        valid_scores.append(roc_auc_score(valid_y, valid_pred_prob))\n",
    "    else:\n",
    "        train_scores.append(accuracy_score(train_y, tree.predict(train_X)))\n",
    "        valid_scores.append(accuracy_score(valid_y, tree.predict(valid_X)))\n",
    "    \n",
    "    # 교차검증\n",
    "    scores = cross_val_score(tree, X, y, cv=5, scoring=scoring)\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# 최적 depth 찾기\n",
    "best_depth_idx = np.argmax(cv_scores)\n",
    "best_depth = list(depths)[best_depth_idx]\n",
    "best_score = cv_scores[best_depth_idx]\n",
    "\n",
    "print(f\"\\n✅ 최적 max_depth: {best_depth}\")\n",
    "print(f\"✅ 최고 CV {metric_name}: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(depths, train_scores, 'o-', label='Train', linewidth=2, markersize=6)\n",
    "plt.plot(depths, valid_scores, 's-', label='Valid', linewidth=2, markersize=6)\n",
    "plt.plot(depths, cv_scores, '^-', label='5-Fold CV', linewidth=2, markersize=6)\n",
    "plt.axvline(best_depth, color='r', linestyle='--', linewidth=2, label=f'Best depth={best_depth}')\n",
    "plt.xlabel('max_depth', fontsize=12, fontweight='bold')\n",
    "plt.ylabel(metric_name, fontsize=12, fontweight='bold')\n",
    "plt.title(f'Model Performance vs max_depth ({metric_name})', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10, loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 최적 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(f\"🏆 최적 모델 (max_depth={best_depth})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tree_best = DecisionTreeClassifier(\n",
    "    max_depth=best_depth,\n",
    "    criterion='entropy',\n",
    "    random_state=1\n",
    ")\n",
    "tree_best.fit(train_X, train_y)\n",
    "\n",
    "# 예측\n",
    "pred_train_y = tree_best.predict(train_X)\n",
    "pred_valid_y = tree_best.predict(valid_X)\n",
    "\n",
    "# 확률 예측\n",
    "if len(np.unique(y)) == 2:\n",
    "    pred_valid_proba = tree_best.predict_proba(valid_X)[:, 1]\n",
    "else:\n",
    "    pred_valid_proba = None\n",
    "\n",
    "print(\"\\n[학습 데이터 성과]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(train_y, pred_train_y, class_names=tree_best.classes_)\n",
    "else:\n",
    "    evaluate_classification(train_y, pred_train_y, model_name=\"Best Tree - Train\")\n",
    "\n",
    "print(\"\\n[검증 데이터 성과]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(valid_y, pred_valid_y, class_names=tree_best.classes_)\n",
    "else:\n",
    "    best_results = evaluate_classification(valid_y, pred_valid_y, pred_valid_proba, \"Best Tree - Valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 기출 대응: 모든 주요 지표 출력\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 최적 모델 교차검증 성과 (모든 지표)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Accuracy\n",
    "scores_acc_best = cross_val_score(tree_best, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"\\n✅ 5-Fold CV Accuracy: {scores_acc_best.mean():.4f} (±{scores_acc_best.std():.4f})\")\n",
    "\n",
    "# F1 Score\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_f1_best = cross_val_score(tree_best, X, y, cv=5, scoring='f1')\n",
    "    print(f\"✅ 5-Fold CV F1 Score: {scores_f1_best.mean():.4f} (±{scores_f1_best.std():.4f})\")\n",
    "else:\n",
    "    scores_f1_best = cross_val_score(tree_best, X, y, cv=5, scoring='f1_weighted')\n",
    "    print(f\"✅ 5-Fold CV F1 Score (weighted): {scores_f1_best.mean():.4f} (±{scores_f1_best.std():.4f})\")\n",
    "\n",
    "# ROC AUC (이진 분류)\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_auc_best = cross_val_score(tree_best, X, y, cv=5, scoring='roc_auc')\n",
    "    print(f\"✅ 5-Fold CV ROC AUC: {scores_auc_best.mean():.4f} (±{scores_auc_best.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 모델의 변수 중요도\n",
    "importance_best = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': tree_best.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n[최적 모델의 변수 중요도 Top 10]\")\n",
    "print(importance_best.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. GridSearchCV로 종합 튜닝 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 하이퍼파라미터 동시 튜닝\n",
    "param_grid = {\n",
    "    'max_depth': list(range(2, 16)),\n",
    "    'min_samples_split': [10, 15, 20],\n",
    "    'min_samples_leaf': [5, 10, 15]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    DecisionTreeClassifier(criterion='entropy', random_state=1),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n⏳ GridSearchCV 진행 중...\")\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"\\n✅ 최적 파라미터: {grid_search.best_params_}\")\n",
    "print(f\"✅ 최고 CV {metric_name}: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 최적 모델\n",
    "tree_grid = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 로지스틱 회귀와 비교 (문제에서 요구시) ⭐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기출: Top 10 또는 Top 5 중요 변수로 로지스틱 회귀\n",
    "top_n_features = 10  # 또는 5 (기출에 따라 변경)\n",
    "top_features = importance_best.head(top_n_features)['feature'].tolist()\n",
    "\n",
    "print(f\"\\nTop {top_n_features} 중요 변수:\")\n",
    "print(top_features)\n",
    "\n",
    "logreg = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "# 교차검증\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"📊 로지스틱 회귀 (Top {top_n_features} 변수) 교차검증\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Accuracy\n",
    "scores_logreg_acc = cross_val_score(logreg, X[top_features], y, cv=5, scoring='accuracy')\n",
    "print(f\"\\n✅ 5-Fold CV Accuracy: {scores_logreg_acc.mean():.4f} (±{scores_logreg_acc.std():.4f})\")\n",
    "\n",
    "# F1 Score\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_logreg_f1 = cross_val_score(logreg, X[top_features], y, cv=5, scoring='f1')\n",
    "    print(f\"✅ 5-Fold CV F1 Score: {scores_logreg_f1.mean():.4f} (±{scores_logreg_f1.std():.4f})\")\n",
    "else:\n",
    "    scores_logreg_f1 = cross_val_score(logreg, X[top_features], y, cv=5, scoring='f1_weighted')\n",
    "    print(f\"✅ 5-Fold CV F1 Score (weighted): {scores_logreg_f1.mean():.4f} (±{scores_logreg_f1.std():.4f})\")\n",
    "\n",
    "# ROC AUC\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_logreg_auc = cross_val_score(logreg, X[top_features], y, cv=5, scoring='roc_auc')\n",
    "    print(f\"✅ 5-Fold CV ROC AUC: {scores_logreg_auc.mean():.4f} (±{scores_logreg_auc.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교 (기출 스타일)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🏆 모델 비교 ({metric_name} 기준)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if scoring == 'roc_auc':\n",
    "    tree_score = scores_auc_best.mean()\n",
    "    logreg_score = scores_logreg_auc.mean()\n",
    "elif scoring == 'f1':\n",
    "    tree_score = scores_f1_best.mean()\n",
    "    logreg_score = scores_logreg_f1.mean()\n",
    "else:\n",
    "    tree_score = scores_acc_best.mean()\n",
    "    logreg_score = scores_logreg_acc.mean()\n",
    "\n",
    "print(f\"\\n의사결정트리 (max_depth={best_depth}): {tree_score:.4f}\")\n",
    "print(f\"로지스틱 회귀 (Top {top_n_features} 변수):  {logreg_score:.4f}\")\n",
    "\n",
    "if tree_score > logreg_score:\n",
    "    print(f\"\\n✅ 의사결정트리가 더 우수 (차이: {tree_score - logreg_score:.4f})\")\n",
    "else:\n",
    "    print(f\"\\n✅ 로지스틱 회귀가 더 우수 (차이: {logreg_score - tree_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 최종 성과 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진 분류인 경우 ROC AUC 계산 및 시각화\n",
    "if len(np.unique(y)) == 2:\n",
    "    valid_pred_prob = tree_best.predict_proba(valid_X)[:, 1]\n",
    "    auc_score = roc_auc_score(valid_y, valid_pred_prob)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📊 ROC Curve\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n최적 의사결정트리 ROC AUC (검증): {auc_score:.4f}\")\n",
    "    \n",
    "    # ROC 곡선\n",
    "    fpr, tpr, thresholds = roc_curve(valid_y, valid_pred_prob)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (AUC = {auc_score:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('ROC Curve - Best Decision Tree', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc=\"lower right\", fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n다중 분류: ROC 곡선은 이진 분류에서만 사용됩니다.\")\n",
    "    print(\"대신 Confusion Matrix를 확인하세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🔍 Confusion Matrix\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cm = confusion_matrix(valid_y, pred_valid_y)\n",
    "print(\"\\n\", cm)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "plt.title('Confusion Matrix - Best Decision Tree', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📋 Classification Report\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n\", classification_report(valid_y, pred_valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 최종 결과 요약 ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"🎯 최종 결과 요약 (기출 대응 완료!)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "✅ 분석 완료!\n",
    "\n",
    "🌳 최적 의사결정트리:\n",
    "   - max_depth: {best_depth}\n",
    "   - criterion: entropy\n",
    "   - 나무 깊이: {tree_best.get_depth()}\n",
    "   - 리프 노드 수: {tree_best.get_n_leaves()}\n",
    "\n",
    "📊 검증 데이터 성과:\n",
    "   - Accuracy:  {best_results['Accuracy']:.4f}  ← 2021년 기출 지표\n",
    "   - F1 Score:  {best_results['F1']:.4f}  ← 2022, 2024년 기출 지표\n",
    "   - Precision: {best_results['Precision']:.4f}\n",
    "   - Recall:    {best_results['Recall']:.4f}\n",
    "\"\"\")\n",
    "\n",
    "if len(np.unique(y)) == 2:\n",
    "    print(f\"   - ROC AUC:   {auc_score:.4f}  ← 2021, 2022, 2023년 기출 지표\")\n",
    "\n",
    "print(f\"\"\"\n",
    "📊 5-Fold CV 성과:\n",
    "   - Accuracy:  {scores_acc_best.mean():.4f} (±{scores_acc_best.std():.4f})\n",
    "   - F1 Score:  {scores_f1_best.mean():.4f} (±{scores_f1_best.std():.4f})\n",
    "\"\"\")\n",
    "\n",
    "if len(np.unique(y)) == 2:\n",
    "    print(f\"   - ROC AUC:   {scores_auc_best.mean():.4f} (±{scores_auc_best.std():.4f})\")\n",
    "\n",
    "print(f\"\"\"\n",
    "🔝 중요 변수 Top 5:\n",
    "   {importance_best.head(5)['feature'].tolist()}\n",
    "\n",
    "🎉 모든 기출 유형 대응 완료!\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
