{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì˜ì‚¬ê²°ì •íŠ¸ë¦¬ ì™„ë²½ í”„ë ˆì„ v2 - ì‹œí—˜ìš© ğŸŒ³\n",
    "## ëª¨ë“  ê¸°ì¶œ ìœ í˜• ëŒ€ì‘! (F1 Score, ROC AUC, Accuracy ëª¨ë‘ í¬í•¨)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# dmba ë¼ì´ë¸ŒëŸ¬ë¦¬ (ìˆìœ¼ë©´)\n",
    "try:\n",
    "    from dmba import classificationSummary\n",
    "    HAS_DMBA = True\n",
    "except:\n",
    "    HAS_DMBA = False\n",
    "    print(\"dmba ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì§€í‘œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ (â­ íŒŒì¼ëª… ìˆ˜ì • í•„ìˆ˜!)\n",
    "df = pd.read_csv('ë°ì´í„°íŒŒì¼.csv')\n",
    "\n",
    "print(\"[ë°ì´í„° ì •ë³´]\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n[ê²°ì¸¡ì¹˜ í™•ì¸]\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n[ë°ì´í„° ìƒ˜í”Œ]\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³€ìˆ˜ íƒ€ì… ìë™ ë¶„ë¥˜\n",
    "print(\"[ë³€ìˆ˜ íƒ€ì… ë¶„ë¥˜]\")\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"ë²”ì£¼í˜• ë³€ìˆ˜ ({len(categorical_cols)}ê°œ): {categorical_cols}\")\n",
    "print(f\"ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ({len(numerical_cols)}ê°œ): {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ì¸¡ì¹˜ ì œê±° (ê¸°ì¶œì—ì„œ ìì£¼ ìš”êµ¬)\n",
    "print(f\"ê²°ì¸¡ì¹˜ ì œê±° ì „: {df.shape}\")\n",
    "df = df.dropna()\n",
    "print(f\"ê²°ì¸¡ì¹˜ ì œê±° í›„: {df.shape}\")\n",
    "\n",
    "# ëª©í‘œë³€ìˆ˜ë¥¼ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜ (í•„ìš”ì‹œ)\n",
    "# df['ëª©í‘œë³€ìˆ˜'] = df['ëª©í‘œë³€ìˆ˜'].astype('category')\n",
    "\n",
    "# ë…ë¦½ë³€ìˆ˜/ì¢…ì†ë³€ìˆ˜ ë¶„ë¦¬ (â­ ì—¬ê¸° ìˆ˜ì • í•„ìˆ˜!)\n",
    "outcome = 'ëª©í‘œë³€ìˆ˜'  # â† ì¢…ì†ë³€ìˆ˜ ì´ë¦„ ì…ë ¥\n",
    "predictors = [col for col in df.columns \n",
    "              if col not in [outcome, 'ì œì™¸í• ë³€ìˆ˜1', 'ì œì™¸í• ë³€ìˆ˜2']]\n",
    "\n",
    "X = df[predictors]\n",
    "y = df[outcome]\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”© (ì˜ì‚¬ê²°ì •íŠ¸ë¦¬ëŠ” drop_first=False ê°€ëŠ¥)\n",
    "X = pd.get_dummies(X, drop_first=False)\n",
    "\n",
    "print(f\"\\në…ë¦½ë³€ìˆ˜ ê°œìˆ˜: {X.shape[1]}\")\n",
    "print(f\"ë°ì´í„° í¬ê¸°: {X.shape}\")\n",
    "print(f\"ë³€ìˆ˜ ëª©ë¡ (ì²˜ìŒ 10ê°œ): {X.columns.tolist()[:10]}\")\n",
    "print(f\"\\nëª©í‘œë³€ìˆ˜ ë¶„í¬:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë°ì´í„° ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°©ë²• 1: train_test_split ì‚¬ìš© (ì¼ë°˜ì )\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {train_X.shape}\")\n",
    "print(f\"ê²€ì¦ ë°ì´í„°: {valid_X.shape}\")\n",
    "print(f\"\\ní•™ìŠµ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:\\n{train_y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°©ë²• 2: ì¸ë±ìŠ¤ ê¸°ë°˜ ë¶„ë¦¬ (ê¸°ì¶œë¬¸ì œ ìŠ¤íƒ€ì¼)\n",
    "# ì˜ˆ: \"0~1999ë²ˆê¹Œì§€ í•™ìŠµ, 2000ë²ˆ~ í…ŒìŠ¤íŠ¸\"\n",
    "\n",
    "# train_X = X.iloc[:2000]\n",
    "# train_y = y.iloc[:2000]\n",
    "# valid_X = X.iloc[2000:]\n",
    "# valid_y = y.iloc[2000:]\n",
    "\n",
    "# print(f\"í•™ìŠµ ë°ì´í„°: {train_X.shape}\")\n",
    "# print(f\"ê²€ì¦ ë°ì´í„°: {valid_X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. í‰ê°€ í•¨ìˆ˜ ì •ì˜ (â­ ê¸°ì¶œ ëŒ€ì‘!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred, y_pred_proba=None, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ - ëª¨ë“  ê¸°ì¶œ ì§€í‘œ í¬í•¨!\n",
    "    \n",
    "    ê¸°ì¶œ ì§€í‘œ:\n",
    "    - Accuracy: 2021ë…„\n",
    "    - F1 Score: 2022ë…„, 2024ë…„\n",
    "    - ROC AUC: 2021ë…„, 2022ë…„, 2023ë…„\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # ì´ì§„ ë¶„ë¥˜ vs ë‹¤ì¤‘ ë¶„ë¥˜\n",
    "    if len(np.unique(y_true)) == 2:\n",
    "        # ì´ì§„ ë¶„ë¥˜\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ğŸ“Š {model_name} ì„±ê³¼ (ì´ì§„ ë¶„ë¥˜)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Accuracy:  {acc:.4f}  â† 2021ë…„ ê¸°ì¶œ\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}  â† 2022, 2024ë…„ ê¸°ì¶œ\")\n",
    "        \n",
    "        if y_pred_proba is not None:\n",
    "            auc = roc_auc_score(y_true, y_pred_proba)\n",
    "            print(f\"ROC AUC:   {auc:.4f}  â† 2021, 2022, 2023ë…„ ê¸°ì¶œ\")\n",
    "        print(f\"{'='*60}\")\n",
    "    else:\n",
    "        # ë‹¤ì¤‘ ë¶„ë¥˜\n",
    "        precision = precision_score(y_true, y_pred, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ğŸ“Š {model_name} ì„±ê³¼ (ë‹¤ì¤‘ ë¶„ë¥˜)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"Precision (weighted): {precision:.4f}\")\n",
    "        print(f\"Recall (weighted):    {recall:.4f}\")\n",
    "        print(f\"F1 Score (weighted):  {f1:.4f}\")\n",
    "        print(f\"{'='*60}\")\n",
    "    \n",
    "    return {'Accuracy': acc, 'Precision': precision, 'Recall': recall, 'F1': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Decision Tree - ê¸°ë³¸ ëª¨ë¸ (Full Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ğŸŒ³ Decision Tree - ê¸°ë³¸ ëª¨ë¸ (ì œì•½ ì—†ìŒ)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± (criterionì€ 'gini' ë˜ëŠ” 'entropy')\n",
    "tree_full = DecisionTreeClassifier(criterion='entropy', random_state=1)\n",
    "tree_full.fit(train_X, train_y)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred_train_y = tree_full.predict(train_X)\n",
    "pred_valid_y = tree_full.predict(valid_X)\n",
    "\n",
    "# í™•ë¥  ì˜ˆì¸¡ (ROC AUCìš©)\n",
    "if len(np.unique(y)) == 2:\n",
    "    pred_valid_proba = tree_full.predict_proba(valid_X)[:, 1]\n",
    "else:\n",
    "    pred_valid_proba = None\n",
    "\n",
    "# ì„±ê³¼ ì¸¡ì •\n",
    "print(\"\\n[í•™ìŠµ ë°ì´í„° ì„±ê³¼]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(train_y, pred_train_y, class_names=tree_full.classes_)\n",
    "else:\n",
    "    evaluate_classification(train_y, pred_train_y, model_name=\"Full Tree - Train\")\n",
    "\n",
    "print(\"\\n[ê²€ì¦ ë°ì´í„° ì„±ê³¼]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(valid_y, pred_valid_y, class_names=tree_full.classes_)\n",
    "else:\n",
    "    evaluate_classification(valid_y, pred_valid_y, pred_valid_proba, \"Full Tree - Valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‚˜ë¬´ êµ¬ì¡° ì •ë³´\n",
    "print(\"\\n[ë‚˜ë¬´ êµ¬ì¡° ì •ë³´]\")\n",
    "print(f\"ìµœëŒ€ ê¹Šì´: {tree_full.get_depth()}\")\n",
    "print(f\"ë¦¬í”„ ë…¸ë“œ ìˆ˜: {tree_full.get_n_leaves()}\")\n",
    "print(f\"ì´ ë…¸ë“œ ìˆ˜: {tree_full.tree_.node_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ ê¸°ì¶œ ëŒ€ì‘: ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œë¡œ êµì°¨ê²€ì¦\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š 5-Fold êµì°¨ê²€ì¦ (ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œ)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Accuracy\n",
    "scores_acc = cross_val_score(tree_full, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"\\nâœ… 5-Fold CV Accuracy: {scores_acc.mean():.4f} (Â±{scores_acc.std():.4f})\")\n",
    "\n",
    "# F1 Score\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_f1 = cross_val_score(tree_full, X, y, cv=5, scoring='f1')\n",
    "    print(f\"âœ… 5-Fold CV F1 Score: {scores_f1.mean():.4f} (Â±{scores_f1.std():.4f})\")\n",
    "else:\n",
    "    scores_f1 = cross_val_score(tree_full, X, y, cv=5, scoring='f1_weighted')\n",
    "    print(f\"âœ… 5-Fold CV F1 Score (weighted): {scores_f1.mean():.4f} (Â±{scores_f1.std():.4f})\")\n",
    "\n",
    "# ROC AUC (ì´ì§„ ë¶„ë¥˜ì¸ ê²½ìš°)\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_auc = cross_val_score(tree_full, X, y, cv=5, scoring='roc_auc')\n",
    "    print(f\"âœ… 5-Fold CV ROC AUC: {scores_auc.mean():.4f} (Â±{scores_auc.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ë³€ìˆ˜ ì¤‘ìš”ë„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameìœ¼ë¡œ ì •ë¦¬\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': tree_full.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n[ë³€ìˆ˜ ì¤‘ìš”ë„ Top 10]\")\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = importance_df.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.title('Top 15 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. max_depth íŠœë‹ ë° ì‹œê°í™” â­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¶œì—ì„œ ìì£¼ ì“°ëŠ” í‰ê°€ ì§€í‘œ ì„ íƒ\n",
    "if len(np.unique(y)) == 2:\n",
    "    scoring = 'roc_auc'  # ì´ì§„ ë¶„ë¥˜: ROC AUC (2021, 2022, 2023)\n",
    "    metric_name = 'ROC AUC'\n",
    "else:\n",
    "    scoring = 'accuracy'  # ë‹¤ì¤‘ ë¶„ë¥˜: Accuracy\n",
    "    metric_name = 'Accuracy'\n",
    "\n",
    "print(f\"\\ní‰ê°€ ì§€í‘œ: {metric_name}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = range(2, 21)\n",
    "train_scores = []\n",
    "valid_scores = []\n",
    "cv_scores = []\n",
    "\n",
    "for depth in depths:\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, criterion='entropy', random_state=1)\n",
    "    tree.fit(train_X, train_y)\n",
    "    \n",
    "    # í•™ìŠµ ë°ì´í„° ì ìˆ˜\n",
    "    if scoring == 'roc_auc':\n",
    "        train_pred_prob = tree.predict_proba(train_X)[:, 1]\n",
    "        valid_pred_prob = tree.predict_proba(valid_X)[:, 1]\n",
    "        train_scores.append(roc_auc_score(train_y, train_pred_prob))\n",
    "        valid_scores.append(roc_auc_score(valid_y, valid_pred_prob))\n",
    "    else:\n",
    "        train_scores.append(accuracy_score(train_y, tree.predict(train_X)))\n",
    "        valid_scores.append(accuracy_score(valid_y, tree.predict(valid_X)))\n",
    "    \n",
    "    # êµì°¨ê²€ì¦\n",
    "    scores = cross_val_score(tree, X, y, cv=5, scoring=scoring)\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# ìµœì  depth ì°¾ê¸°\n",
    "best_depth_idx = np.argmax(cv_scores)\n",
    "best_depth = list(depths)[best_depth_idx]\n",
    "best_score = cv_scores[best_depth_idx]\n",
    "\n",
    "print(f\"\\nâœ… ìµœì  max_depth: {best_depth}\")\n",
    "print(f\"âœ… ìµœê³  CV {metric_name}: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(depths, train_scores, 'o-', label='Train', linewidth=2, markersize=6)\n",
    "plt.plot(depths, valid_scores, 's-', label='Valid', linewidth=2, markersize=6)\n",
    "plt.plot(depths, cv_scores, '^-', label='5-Fold CV', linewidth=2, markersize=6)\n",
    "plt.axvline(best_depth, color='r', linestyle='--', linewidth=2, label=f'Best depth={best_depth}')\n",
    "plt.xlabel('max_depth', fontsize=12, fontweight='bold')\n",
    "plt.ylabel(metric_name, fontsize=12, fontweight='bold')\n",
    "plt.title(f'Model Performance vs max_depth ({metric_name})', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10, loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ìµœì  ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(f\"ğŸ† ìµœì  ëª¨ë¸ (max_depth={best_depth})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tree_best = DecisionTreeClassifier(\n",
    "    max_depth=best_depth,\n",
    "    criterion='entropy',\n",
    "    random_state=1\n",
    ")\n",
    "tree_best.fit(train_X, train_y)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred_train_y = tree_best.predict(train_X)\n",
    "pred_valid_y = tree_best.predict(valid_X)\n",
    "\n",
    "# í™•ë¥  ì˜ˆì¸¡\n",
    "if len(np.unique(y)) == 2:\n",
    "    pred_valid_proba = tree_best.predict_proba(valid_X)[:, 1]\n",
    "else:\n",
    "    pred_valid_proba = None\n",
    "\n",
    "print(\"\\n[í•™ìŠµ ë°ì´í„° ì„±ê³¼]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(train_y, pred_train_y, class_names=tree_best.classes_)\n",
    "else:\n",
    "    evaluate_classification(train_y, pred_train_y, model_name=\"Best Tree - Train\")\n",
    "\n",
    "print(\"\\n[ê²€ì¦ ë°ì´í„° ì„±ê³¼]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(valid_y, pred_valid_y, class_names=tree_best.classes_)\n",
    "else:\n",
    "    best_results = evaluate_classification(valid_y, pred_valid_y, pred_valid_proba, \"Best Tree - Valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ ê¸°ì¶œ ëŒ€ì‘: ëª¨ë“  ì£¼ìš” ì§€í‘œ ì¶œë ¥\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ìµœì  ëª¨ë¸ êµì°¨ê²€ì¦ ì„±ê³¼ (ëª¨ë“  ì§€í‘œ)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Accuracy\n",
    "scores_acc_best = cross_val_score(tree_best, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"\\nâœ… 5-Fold CV Accuracy: {scores_acc_best.mean():.4f} (Â±{scores_acc_best.std():.4f})\")\n",
    "\n",
    "# F1 Score\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_f1_best = cross_val_score(tree_best, X, y, cv=5, scoring='f1')\n",
    "    print(f\"âœ… 5-Fold CV F1 Score: {scores_f1_best.mean():.4f} (Â±{scores_f1_best.std():.4f})\")\n",
    "else:\n",
    "    scores_f1_best = cross_val_score(tree_best, X, y, cv=5, scoring='f1_weighted')\n",
    "    print(f\"âœ… 5-Fold CV F1 Score (weighted): {scores_f1_best.mean():.4f} (Â±{scores_f1_best.std():.4f})\")\n",
    "\n",
    "# ROC AUC (ì´ì§„ ë¶„ë¥˜)\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_auc_best = cross_val_score(tree_best, X, y, cv=5, scoring='roc_auc')\n",
    "    print(f\"âœ… 5-Fold CV ROC AUC: {scores_auc_best.mean():.4f} (Â±{scores_auc_best.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì  ëª¨ë¸ì˜ ë³€ìˆ˜ ì¤‘ìš”ë„\n",
    "importance_best = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': tree_best.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n[ìµœì  ëª¨ë¸ì˜ ë³€ìˆ˜ ì¤‘ìš”ë„ Top 10]\")\n",
    "print(importance_best.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. GridSearchCVë¡œ ì¢…í•© íŠœë‹ (ì„ íƒì‚¬í•­)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ëŸ¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë™ì‹œ íŠœë‹\n",
    "param_grid = {\n",
    "    'max_depth': list(range(2, 16)),\n",
    "    'min_samples_split': [10, 15, 20],\n",
    "    'min_samples_leaf': [5, 10, 15]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    DecisionTreeClassifier(criterion='entropy', random_state=1),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâ³ GridSearchCV ì§„í–‰ ì¤‘...\")\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"\\nâœ… ìµœì  íŒŒë¼ë¯¸í„°: {grid_search.best_params_}\")\n",
    "print(f\"âœ… ìµœê³  CV {metric_name}: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ìµœì  ëª¨ë¸\n",
    "tree_grid = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ë¡œì§€ìŠ¤í‹± íšŒê·€ì™€ ë¹„êµ (ë¬¸ì œì—ì„œ ìš”êµ¬ì‹œ) â­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¶œ: Top 10 ë˜ëŠ” Top 5 ì¤‘ìš” ë³€ìˆ˜ë¡œ ë¡œì§€ìŠ¤í‹± íšŒê·€\n",
    "top_n_features = 10  # ë˜ëŠ” 5 (ê¸°ì¶œì— ë”°ë¼ ë³€ê²½)\n",
    "top_features = importance_best.head(top_n_features)['feature'].tolist()\n",
    "\n",
    "print(f\"\\nTop {top_n_features} ì¤‘ìš” ë³€ìˆ˜:\")\n",
    "print(top_features)\n",
    "\n",
    "logreg = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "# êµì°¨ê²€ì¦\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ“Š ë¡œì§€ìŠ¤í‹± íšŒê·€ (Top {top_n_features} ë³€ìˆ˜) êµì°¨ê²€ì¦\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Accuracy\n",
    "scores_logreg_acc = cross_val_score(logreg, X[top_features], y, cv=5, scoring='accuracy')\n",
    "print(f\"\\nâœ… 5-Fold CV Accuracy: {scores_logreg_acc.mean():.4f} (Â±{scores_logreg_acc.std():.4f})\")\n",
    "\n",
    "# F1 Score\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_logreg_f1 = cross_val_score(logreg, X[top_features], y, cv=5, scoring='f1')\n",
    "    print(f\"âœ… 5-Fold CV F1 Score: {scores_logreg_f1.mean():.4f} (Â±{scores_logreg_f1.std():.4f})\")\n",
    "else:\n",
    "    scores_logreg_f1 = cross_val_score(logreg, X[top_features], y, cv=5, scoring='f1_weighted')\n",
    "    print(f\"âœ… 5-Fold CV F1 Score (weighted): {scores_logreg_f1.mean():.4f} (Â±{scores_logreg_f1.std():.4f})\")\n",
    "\n",
    "# ROC AUC\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_logreg_auc = cross_val_score(logreg, X[top_features], y, cv=5, scoring='roc_auc')\n",
    "    print(f\"âœ… 5-Fold CV ROC AUC: {scores_logreg_auc.mean():.4f} (Â±{scores_logreg_auc.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„êµ (ê¸°ì¶œ ìŠ¤íƒ€ì¼)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ† ëª¨ë¸ ë¹„êµ ({metric_name} ê¸°ì¤€)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if scoring == 'roc_auc':\n",
    "    tree_score = scores_auc_best.mean()\n",
    "    logreg_score = scores_logreg_auc.mean()\n",
    "elif scoring == 'f1':\n",
    "    tree_score = scores_f1_best.mean()\n",
    "    logreg_score = scores_logreg_f1.mean()\n",
    "else:\n",
    "    tree_score = scores_acc_best.mean()\n",
    "    logreg_score = scores_logreg_acc.mean()\n",
    "\n",
    "print(f\"\\nì˜ì‚¬ê²°ì •íŠ¸ë¦¬ (max_depth={best_depth}): {tree_score:.4f}\")\n",
    "print(f\"ë¡œì§€ìŠ¤í‹± íšŒê·€ (Top {top_n_features} ë³€ìˆ˜):  {logreg_score:.4f}\")\n",
    "\n",
    "if tree_score > logreg_score:\n",
    "    print(f\"\\nâœ… ì˜ì‚¬ê²°ì •íŠ¸ë¦¬ê°€ ë” ìš°ìˆ˜ (ì°¨ì´: {tree_score - logreg_score:.4f})\")\n",
    "else:\n",
    "    print(f\"\\nâœ… ë¡œì§€ìŠ¤í‹± íšŒê·€ê°€ ë” ìš°ìˆ˜ (ì°¨ì´: {logreg_score - tree_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. ìµœì¢… ì„±ê³¼ ë° ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ì§„ ë¶„ë¥˜ì¸ ê²½ìš° ROC AUC ê³„ì‚° ë° ì‹œê°í™”\n",
    "if len(np.unique(y)) == 2:\n",
    "    valid_pred_prob = tree_best.predict_proba(valid_X)[:, 1]\n",
    "    auc_score = roc_auc_score(valid_y, valid_pred_prob)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š ROC Curve\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nìµœì  ì˜ì‚¬ê²°ì •íŠ¸ë¦¬ ROC AUC (ê²€ì¦): {auc_score:.4f}\")\n",
    "    \n",
    "    # ROC ê³¡ì„ \n",
    "    fpr, tpr, thresholds = roc_curve(valid_y, valid_pred_prob)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (AUC = {auc_score:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('ROC Curve - Best Decision Tree', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc=\"lower right\", fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\në‹¤ì¤‘ ë¶„ë¥˜: ROC ê³¡ì„ ì€ ì´ì§„ ë¶„ë¥˜ì—ì„œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\")\n",
    "    print(\"ëŒ€ì‹  Confusion Matrixë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ” Confusion Matrix\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cm = confusion_matrix(valid_y, pred_valid_y)\n",
    "print(\"\\n\", cm)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "plt.title('Confusion Matrix - Best Decision Tree', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“‹ Classification Report\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n\", classification_report(valid_y, pred_valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. ìµœì¢… ê²°ê³¼ ìš”ì•½ âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ğŸ¯ ìµœì¢… ê²°ê³¼ ìš”ì•½ (ê¸°ì¶œ ëŒ€ì‘ ì™„ë£Œ!)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… ë¶„ì„ ì™„ë£Œ!\n",
    "\n",
    "ğŸŒ³ ìµœì  ì˜ì‚¬ê²°ì •íŠ¸ë¦¬:\n",
    "   - max_depth: {best_depth}\n",
    "   - criterion: entropy\n",
    "   - ë‚˜ë¬´ ê¹Šì´: {tree_best.get_depth()}\n",
    "   - ë¦¬í”„ ë…¸ë“œ ìˆ˜: {tree_best.get_n_leaves()}\n",
    "\n",
    "ğŸ“Š ê²€ì¦ ë°ì´í„° ì„±ê³¼:\n",
    "   - Accuracy:  {best_results['Accuracy']:.4f}  â† 2021ë…„ ê¸°ì¶œ ì§€í‘œ\n",
    "   - F1 Score:  {best_results['F1']:.4f}  â† 2022, 2024ë…„ ê¸°ì¶œ ì§€í‘œ\n",
    "   - Precision: {best_results['Precision']:.4f}\n",
    "   - Recall:    {best_results['Recall']:.4f}\n",
    "\"\"\")\n",
    "\n",
    "if len(np.unique(y)) == 2:\n",
    "    print(f\"   - ROC AUC:   {auc_score:.4f}  â† 2021, 2022, 2023ë…„ ê¸°ì¶œ ì§€í‘œ\")\n",
    "\n",
    "print(f\"\"\"\n",
    "ğŸ“Š 5-Fold CV ì„±ê³¼:\n",
    "   - Accuracy:  {scores_acc_best.mean():.4f} (Â±{scores_acc_best.std():.4f})\n",
    "   - F1 Score:  {scores_f1_best.mean():.4f} (Â±{scores_f1_best.std():.4f})\n",
    "\"\"\")\n",
    "\n",
    "if len(np.unique(y)) == 2:\n",
    "    print(f\"   - ROC AUC:   {scores_auc_best.mean():.4f} (Â±{scores_auc_best.std():.4f})\")\n",
    "\n",
    "print(f\"\"\"\n",
    "ğŸ” ì¤‘ìš” ë³€ìˆ˜ Top 5:\n",
    "   {importance_best.head(5)['feature'].tolist()}\n",
    "\n",
    "ğŸ‰ ëª¨ë“  ê¸°ì¶œ ìœ í˜• ëŒ€ì‘ ì™„ë£Œ!\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
