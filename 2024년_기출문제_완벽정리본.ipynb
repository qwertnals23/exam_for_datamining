{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📝 2024년 데이터마이닝 중간고사 기출문제 - 완벽 정리본\n",
    "## ⭐ 시험장에서 바로 이해할 수 있도록 주석 완비!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제 1. 로지스틱 회귀분석 (Phishing 분류) - 40점\n",
    "\n",
    "## 🎯 목표: 웹사이트가 피싱 사이트인지 분류\n",
    "- **데이터**: web-page-phishing.csv\n",
    "- **목표변수**: phishing (1: 피싱, 0: 정상)\n",
    "- **모델**: 로지스틱 회귀\n",
    "- **핵심 평가지표**: F1 Score, ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 🔹 분류 모델 라이브러리 (문제 1, 2용)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression  # ← 로지스틱 회귀\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree  # ← 의사결정트리\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# 🔹 회귀 모델 라이브러리 (문제 3용)\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# dmba 라이브러리 (선택사항)\n",
    "try:\n",
    "    from dmba import classificationSummary, regressionSummary\n",
    "    HAS_DMBA = True\n",
    "    print(\"✅ dmba 라이브러리 사용 가능\")\n",
    "except:\n",
    "    HAS_DMBA = False\n",
    "    print(\"⚠️ dmba 없음 - sklearn metrics만 사용\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1-(1) 데이터 전처리\n",
    "\n",
    "### 📌 요구사항\n",
    "- 입력변수: phishing 제외한 모든 변수\n",
    "- 데이터 전처리 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1-(1) 데이터 로드 및 탐색\n",
    "# ========================================\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('web-page-phishing.csv')  # ← ⭐ 파일명 확인!\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"📊 데이터 정보\")\n",
    "print(\"=\"*60)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🔍 결측치 확인\")\n",
    "print(\"=\"*60)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"👀 데이터 샘플 (처음 5개)\")\n",
    "print(\"=\"*60)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 변수 타입 자동 분류\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"🔍 변수 타입 분류\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"\\n범주형 변수 ({len(categorical_cols)}개): {categorical_cols}\")\n",
    "print(f\"수치형 변수 ({len(numerical_cols)}개): {numerical_cols}\")\n",
    "\n",
    "# 💡 이 데이터는 모두 수치형일 가능성 높음 (URL 특징들)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 독립변수 / 종속변수 분리\n",
    "# ========================================\n",
    "\n",
    "# 🎯 목표변수 설정\n",
    "outcome = 'phishing'  # ← 문제에서 지정\n",
    "\n",
    "# 🔹 독립변수 = 목표변수 제외한 모든 변수\n",
    "predictors = [col for col in df.columns if col != outcome]\n",
    "\n",
    "X = df[predictors]\n",
    "y = df[outcome]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"📊 변수 분리 완료\")\n",
    "print(\"=\"*60)\n",
    "print(f\"독립변수 개수: {len(predictors)}개\")\n",
    "print(f\"데이터 크기: {X.shape}\")\n",
    "print(f\"\\n목표변수 분포:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\n목표변수 비율:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "# 💡 이진 분류 문제 확인!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 범주형 변수 원-핫 인코딩 (필요시)\n",
    "# ========================================\n",
    "\n",
    "# 이 데이터는 모두 수치형이라 인코딩 불필요할 가능성 높음\n",
    "# 하지만 범주형이 있다면 아래 코드 실행\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    print(f\"\\n범주형 변수 인코딩 중: {categorical_cols}\")\n",
    "    X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "    print(f\"인코딩 후 변수 개수: {X.shape[1]}개\")\n",
    "else:\n",
    "    print(\"\\n✅ 범주형 변수 없음 - 인코딩 불필요\")\n",
    "\n",
    "print(f\"\\n최종 독립변수 개수: {X.shape[1]}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1-(2) 데이터 분리\n",
    "\n",
    "### 📌 요구사항\n",
    "- 무작위 분리\n",
    "- **테스트 20%**, 학습 80%\n",
    "- random_state 설정 (재현성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1-(2) 학습/테스트 데이터 분할\n",
    "# ========================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # ← ⭐ 문제에서 지정: 테스트 20%\n",
    "    random_state=42,    # ← 재현성 (아무 숫자나 가능, 1도 괜찮음)\n",
    "    stratify=y          # ← 클래스 비율 유지 (권장)\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"✂️ 데이터 분리 완료\")\n",
    "print(\"=\"*60)\n",
    "print(f\"학습 데이터: {X_train.shape} (80%)\")\n",
    "print(f\"테스트 데이터: {X_test.shape} (20%)\")\n",
    "print(f\"\\n학습 데이터 클래스 분포:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\n테스트 데이터 클래스 분포:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1-(3) 로지스틱 회귀 학습 및 F1 Score 측정\n",
    "\n",
    "### 📌 요구사항\n",
    "- 로지스틱 회귀 모델 학습\n",
    "- 테스트 데이터로 예측\n",
    "- **F1 Score로 평가** ← ⭐ 핵심!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1-(3) 로지스틱 회귀 모델 학습\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"📊 로지스틱 회귀 모델 (기본)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 모델 생성 및 학습\n",
    "logreg = LogisticRegression(\n",
    "    max_iter=1000,      # ← 수렴 보장\n",
    "    random_state=42     # ← 재현성\n",
    ")\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ 모델 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 예측 수행\n",
    "# ========================================\n",
    "\n",
    "# 학습 데이터 예측\n",
    "y_pred_train = logreg.predict(X_train)\n",
    "\n",
    "# 테스트 데이터 예측 (⭐ 문제에서 요구)\n",
    "y_pred_test = logreg.predict(X_test)\n",
    "\n",
    "print(\"✅ 예측 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# F1 Score 측정 (⭐ 문제에서 요구!)\n",
    "# ========================================\n",
    "\n",
    "# 학습 데이터 F1 Score\n",
    "f1_train = f1_score(y_train, y_pred_train)\n",
    "\n",
    "# 테스트 데이터 F1 Score (⭐ 핵심!)\n",
    "f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 문제 1-(3) 결과: F1 Score\")\n",
    "print(\"=\"*60)\n",
    "print(f\"학습 데이터 F1 Score:  {f1_train:.4f}\")\n",
    "print(f\"테스트 데이터 F1 Score: {f1_test:.4f}  ← ⭐ 답안!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 추가 지표들 (참고용)\n",
    "print(f\"\\n[추가 성과 지표 - 테스트 데이터]\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1-(4) 5겹 교차검증 (F1 Score)\n",
    "\n",
    "### 📌 요구사항\n",
    "- **5겹 교차검증**\n",
    "- **F1 Score로 평가**\n",
    "- **solver='newton-cholesky'** ← ⭐ 문제에서 지정!\n",
    "- 평균치 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1-(4) 5겹 교차검증 (F1 Score)\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"🔄 5겹 교차검증 (solver='newton-cholesky')\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 모델 생성 (⭐ solver 지정 필수!)\n",
    "logreg_cv = LogisticRegression(\n",
    "    solver='newton-cholesky',  # ← ⭐ 문제에서 지정!\n",
    "    max_iter=1000,             # ← 수렴 보장\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 5겹 교차검증 수행\n",
    "cv_scores = cross_val_score(\n",
    "    logreg_cv, \n",
    "    X_train,        # ← 학습 데이터만 사용\n",
    "    y_train, \n",
    "    cv=5,           # ← ⭐ 5겹\n",
    "    scoring='f1',   # ← ⭐ F1 Score\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 문제 1-(4) 결과: 5겹 교차검증\")\n",
    "print(\"=\"*60)\n",
    "print(f\"5-Fold CV F1 Score: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
    "print(f\"\\n각 Fold 점수: {cv_scores}\")\n",
    "print(f\"\\n평균: {cv_scores.mean():.4f}  ← ⭐ 답안!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1-(5) 하이퍼파라미터 튜닝 (C 튜닝)\n",
    "\n",
    "### 📌 요구사항\n",
    "- **파라미터**: C (정규화 강도의 역수)\n",
    "- **평가 지표**: ROC AUC ← ⭐ F1에서 변경!\n",
    "- **교차검증**: 10겹 ← ⭐ 5겹에서 변경!\n",
    "- **solver='newton-cholesky'**\n",
    "- 최적 C 값 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1-(5) C 하이퍼파라미터 튜닝\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"🔧 하이퍼파라미터 튜닝 (C)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# C 값 후보 정의\n",
    "# C의 default = 1.0\n",
    "# C가 작을수록 강한 규제, 클수록 약한 규제\n",
    "param_grid = {\n",
    "    'C': np.logspace(-3, 3, 20)  # 0.001 ~ 1000 사이 20개 값\n",
    "}\n",
    "\n",
    "# GridSearchCV 설정\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(\n",
    "        solver='newton-cholesky',  # ← ⭐ 문제에서 지정!\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    ),\n",
    "    param_grid,\n",
    "    cv=10,              # ← ⭐ 10겹 교차검증\n",
    "    scoring='roc_auc',  # ← ⭐ ROC AUC로 평가\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n⏳ GridSearchCV 진행 중...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 문제 1-(5) 결과: 최적 C 값\")\n",
    "print(\"=\"*60)\n",
    "print(f\"최적 C 값: {grid_search.best_params_['C']:.6f}  ← ⭐ 답안!\")\n",
    "print(f\"최고 CV ROC AUC: {grid_search.best_score_:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 최적 모델로 테스트 데이터 평가\n",
    "# ========================================\n",
    "\n",
    "best_logreg = grid_search.best_estimator_\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "y_pred_test_best = best_logreg.predict(X_test)\n",
    "y_pred_proba_test = best_logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 성과 측정\n",
    "f1_test_best = f1_score(y_test, y_pred_test_best)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 최적 모델 테스트 성과\")\n",
    "print(\"=\"*60)\n",
    "print(f\"F1 Score:  {f1_test_best:.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_test:.4f}\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_test_best):.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 문제 2. 의사결정트리 (Phishing 분류) - 20점\n",
    "\n",
    "## 🎯 목표: 같은 데이터로 의사결정트리 모델 만들기\n",
    "- **데이터**: 문제 1과 동일 (web-page-phishing.csv)\n",
    "- **모델**: 의사결정트리\n",
    "- **핵심**: max_depth 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 2-(1) 최대 나무 모델 (Full Tree)\n",
    "\n",
    "### 📌 요구사항\n",
    "- 문제 1의 전처리된 학습집합 사용\n",
    "- 최대 나무 (제약 없음)\n",
    "- 테스트집합으로 F1 Score 측정\n",
    "- default 불순도 지표 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 2-(1) 최대 의사결정트리 모델\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"🌳 의사결정트리 - 최대 나무 (Full Tree)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 모델 생성 (제약 없음)\n",
    "tree_full = DecisionTreeClassifier(\n",
    "    random_state=42  # ← 재현성\n",
    "    # criterion='gini'  ← default (생략 가능)\n",
    "    # max_depth=None    ← default (생략 가능)\n",
    ")\n",
    "\n",
    "# 학습\n",
    "tree_full.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ 모델 학습 완료!\")\n",
    "print(f\"\\n[나무 구조 정보]\")\n",
    "print(f\"최대 깊이: {tree_full.get_depth()}\")\n",
    "print(f\"리프 노드 수: {tree_full.get_n_leaves()}\")\n",
    "print(f\"총 노드 수: {tree_full.tree_.node_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 테스트 데이터 평가 (F1 Score)\n",
    "# ========================================\n",
    "\n",
    "# 예측\n",
    "y_pred_test_tree = tree_full.predict(X_test)\n",
    "\n",
    "# F1 Score 계산\n",
    "f1_test_tree_full = f1_score(y_test, y_pred_test_tree)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 문제 2-(1) 결과: 최대 나무 F1 Score\")\n",
    "print(\"=\"*60)\n",
    "print(f\"테스트 데이터 F1 Score: {f1_test_tree_full:.4f}  ← ⭐ 답안!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 추가 지표\n",
    "print(f\"\\n[추가 성과 지표]\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_test_tree):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test_tree):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_test_tree):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 2-(2) max_depth 튜닝\n",
    "\n",
    "### 📌 요구사항\n",
    "- max_depth를 2~20까지 변화\n",
    "- 각 depth마다 F1 Score 측정\n",
    "- 학습/테스트 데이터로 성과 비교\n",
    "- 가장 좋은 max_depth 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 2-(2) max_depth 튜닝\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"🔧 max_depth 튜닝 (2~20)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "depths = range(2, 21)  # 2부터 20까지\n",
    "train_f1_scores = []\n",
    "test_f1_scores = []\n",
    "\n",
    "for depth in depths:\n",
    "    # 모델 생성\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 학습\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    # 학습 데이터 F1 Score\n",
    "    train_pred = tree.predict(X_train)\n",
    "    train_f1 = f1_score(y_train, train_pred)\n",
    "    train_f1_scores.append(train_f1)\n",
    "    \n",
    "    # 테스트 데이터 F1 Score\n",
    "    test_pred = tree.predict(X_test)\n",
    "    test_f1 = f1_score(y_test, test_pred)\n",
    "    test_f1_scores.append(test_f1)\n",
    "\n",
    "# 최적 depth 찾기\n",
    "best_depth_idx = np.argmax(test_f1_scores)\n",
    "best_depth = list(depths)[best_depth_idx]\n",
    "best_f1 = test_f1_scores[best_depth_idx]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 문제 2-(2) 결과: 최적 max_depth\")\n",
    "print(\"=\"*60)\n",
    "print(f\"최적 max_depth: {best_depth}  ← ⭐ 답안!\")\n",
    "print(f\"테스트 F1 Score: {best_f1:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# max_depth별 성과 시각화\n",
    "# ========================================\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(depths, train_f1_scores, 'o-', label='Train F1', linewidth=2, markersize=6)\n",
    "plt.plot(depths, test_f1_scores, 's-', label='Test F1', linewidth=2, markersize=6)\n",
    "plt.axvline(best_depth, color='r', linestyle='--', linewidth=2, \n",
    "            label=f'Best depth={best_depth}')\n",
    "plt.xlabel('max_depth', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
    "plt.title('F1 Score vs max_depth', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 과적합 여부 확인:\")\n",
    "print(f\"학습 F1: {train_f1_scores[best_depth_idx]:.4f}\")\n",
    "print(f\"테스트 F1: {test_f1_scores[best_depth_idx]:.4f}\")\n",
    "print(f\"차이: {train_f1_scores[best_depth_idx] - test_f1_scores[best_depth_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 2-(3) 최적 모델의 변수 중요도\n",
    "\n",
    "### 📌 요구사항\n",
    "- 2-(2)에서 찾은 최적 depth 모델 사용\n",
    "- 입력 변수 중요도 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 2-(3) 변수 중요도 분석\n",
    "# ========================================\n",
    "\n",
    "# 최적 depth로 모델 재학습\n",
    "tree_best = DecisionTreeClassifier(\n",
    "    max_depth=best_depth,\n",
    "    random_state=42\n",
    ")\n",
    "tree_best.fit(X_train, y_train)\n",
    "\n",
    "# 변수 중요도 추출\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': tree_best.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"📊 문제 2-(3) 결과: 변수 중요도\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n[Top 10 중요 변수]\")\n",
    "print(importance_df.head(10).to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_15 = importance_df.head(15)\n",
    "plt.barh(range(len(top_15)), top_15['importance'])\n",
    "plt.yticks(range(len(top_15)), top_15['feature'])\n",
    "plt.xlabel('Importance', fontsize=12, fontweight='bold')\n",
    "plt.title('Top 15 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 문제 3. 회귀분석 (Insurance 청구비용 예측) - 35점\n",
    "\n",
    "## 🎯 목표: 보험 청구비용 예측\n",
    "- **데이터**: insurance.csv\n",
    "- **목표변수**: charges (청구비용)\n",
    "- **모델**: Linear Regression, Lasso\n",
    "- **핵심 평가지표**: MAPE, MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 3-(1) 데이터 전처리\n",
    "\n",
    "### 📌 요구사항\n",
    "- 종속변수: charges\n",
    "- 독립변수: 나머지 모든 변수\n",
    "- **범주형 변수**: 원-핫 인코딩\n",
    "- **수치형 변수**: 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3-(1) 데이터 로드 및 탐색\n",
    "# ========================================\n",
    "\n",
    "df_ins = pd.read_csv('insurance.csv')  # ← ⭐ 파일명 확인!\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"📊 Insurance 데이터 정보\")\n",
    "print(\"=\"*60)\n",
    "df_ins.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🔍 결측치 확인\")\n",
    "print(\"=\"*60)\n",
    "print(df_ins.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"👀 데이터 샘플\")\n",
    "print(\"=\"*60)\n",
    "print(df_ins.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 변수 타입 분류\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"🔍 변수 타입 분류\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "categorical_cols_ins = df_ins.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols_ins = df_ins.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"\\n범주형 변수: {categorical_cols_ins}\")\n",
    "print(f\"수치형 변수: {numerical_cols_ins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 독립변수/종속변수 분리\n",
    "# ========================================\n",
    "\n",
    "outcome_ins = 'charges'  # ← 목표변수\n",
    "predictors_ins = [col for col in df_ins.columns if col != outcome_ins]\n",
    "\n",
    "X_ins = df_ins[predictors_ins]\n",
    "y_ins = df_ins[outcome_ins]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"📊 변수 분리\")\n",
    "print(\"=\"*60)\n",
    "print(f\"독립변수: {predictors_ins}\")\n",
    "print(f\"종속변수: {outcome_ins}\")\n",
    "print(f\"\\n종속변수 기본 통계:\")\n",
    "print(y_ins.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 범주형 변수 원-핫 인코딩\n",
    "# ========================================\n",
    "\n",
    "# 범주형 변수만 인코딩\n",
    "categorical_in_X = [col for col in categorical_cols_ins if col in X_ins.columns]\n",
    "\n",
    "if len(categorical_in_X) > 0:\n",
    "    print(f\"\\n원-핫 인코딩 대상: {categorical_in_X}\")\n",
    "    X_ins = pd.get_dummies(X_ins, columns=categorical_in_X, drop_first=True)\n",
    "    print(f\"인코딩 후 변수 개수: {X_ins.shape[1]}개\")\n",
    "\n",
    "print(f\"\\n최종 독립변수 목록: {X_ins.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 수치형 변수 표준화\n",
    "# ========================================\n",
    "\n",
    "# 수치형 변수 찾기 (원-핫 인코딩 후 기준)\n",
    "numerical_in_X = X_ins.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "if len(numerical_in_X) > 0:\n",
    "    scaler_ins = StandardScaler()\n",
    "    X_ins[numerical_in_X] = scaler_ins.fit_transform(X_ins[numerical_in_X])\n",
    "    print(f\"\\n✅ 표준화 완료: {numerical_in_X}\")\n",
    "\n",
    "print(f\"\\n최종 데이터 크기: {X_ins.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 3-(2) 회귀분석 모형 학습\n",
    "\n",
    "### 📌 요구사항\n",
    "- 전체 데이터를 **20% 테스트**, 80% 학습으로 분리\n",
    "- 학습집합으로 회귀분석 모형 학습\n",
    "- 청구비용에 유의미한 영향을 미치는 변수 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3-(2) 데이터 분리\n",
    "# ========================================\n",
    "\n",
    "X_train_ins, X_test_ins, y_train_ins, y_test_ins = train_test_split(\n",
    "    X_ins, y_ins,\n",
    "    test_size=0.2,     # ← ⭐ 테스트 20%\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"✂️ 데이터 분리\")\n",
    "print(\"=\"*60)\n",
    "print(f\"학습 데이터: {X_train_ins.shape} (80%)\")\n",
    "print(f\"테스트 데이터: {X_test_ins.shape} (20%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 회귀분석 모형 학습\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 Linear Regression 학습\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lr_ins = LinearRegression()\n",
    "lr_ins.fit(X_train_ins, y_train_ins)\n",
    "\n",
    "print(\"✅ 모델 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 회귀계수 확인 (유의미한 변수 파악)\n",
    "# ========================================\n",
    "\n",
    "coef_df_ins = pd.DataFrame({\n",
    "    'Variable': X_train_ins.columns,\n",
    "    'Coefficient': lr_ins.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 문제 3-(2) 결과: 회귀계수\")\n",
    "print(\"=\"*60)\n",
    "print(f\"절편(Intercept): {lr_ins.intercept_:.4f}\")\n",
    "print(f\"\\n회귀계수 (절대값 기준 정렬):\")\n",
    "print(coef_df_ins.to_string(index=False))\n",
    "print(\"\\n💡 계수의 절대값이 클수록 영향력이 큼!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 3-(3) 회귀분석 성과 측정 (MAPE)\n",
    "\n",
    "### 📌 요구사항\n",
    "- 테스트집합으로 예측\n",
    "- **MAPE로 성과 측정** ← ⭐ 핵심!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3-(3) 예측 및 MAPE 측정\n",
    "# ========================================\n",
    "\n",
    "# 예측\n",
    "y_pred_train_ins = lr_ins.predict(X_train_ins)\n",
    "y_pred_test_ins = lr_ins.predict(X_test_ins)\n",
    "\n",
    "# MAPE 계산 (⭐ 문제에서 요구!)\n",
    "mape_train = mean_absolute_percentage_error(y_train_ins, y_pred_train_ins) * 100\n",
    "mape_test = mean_absolute_percentage_error(y_test_ins, y_pred_test_ins) * 100\n",
    "\n",
    "# 추가 지표들\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_ins, y_pred_test_ins))\n",
    "mae_test = mean_absolute_error(y_test_ins, y_pred_test_ins)\n",
    "r2_test = lr_ins.score(X_test_ins, y_test_ins)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"📊 문제 3-(3) 결과: 회귀분석 성과\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n[학습 데이터]\")\n",
    "print(f\"MAPE: {mape_train:.2f}%\")\n",
    "\n",
    "print(f\"\\n[테스트 데이터]  ← ⭐ 답안!\")\n",
    "print(f\"MAPE: {mape_test:.2f}%  ← ⭐ 문제에서 요구한 지표!\")\n",
    "print(f\"\\n[추가 지표]\")\n",
    "print(f\"RMSE: {rmse_test:,.2f}\")\n",
    "print(f\"MAE:  {mae_test:,.2f}\")\n",
    "print(f\"R²:   {r2_test:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 3-(4) Lasso 하이퍼파라미터 튜닝\n",
    "\n",
    "### 📌 요구사항\n",
    "- **학습집합만** 사용 (테스트집합 사용 X)\n",
    "- alpha 파라미터 튜닝\n",
    "- **10겹 교차검증**\n",
    "- **MSE로 평가** ← ⭐ scoring='neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3-(4) Lasso alpha 튜닝\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"🔧 Lasso 하이퍼파라미터 튜닝 (alpha)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# alpha 후보 정의\n",
    "param_grid_lasso = {\n",
    "    'alpha': np.logspace(-4, 2, 100)  # 0.0001 ~ 100 사이 100개 값\n",
    "}\n",
    "\n",
    "# GridSearchCV 설정\n",
    "grid_search_lasso = GridSearchCV(\n",
    "    Lasso(max_iter=10000, random_state=42),\n",
    "    param_grid_lasso,\n",
    "    cv=10,                          # ← ⭐ 10겹 교차검증\n",
    "    scoring='neg_mean_squared_error',  # ← ⭐ MSE로 평가\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n⏳ GridSearchCV 진행 중... (학습 데이터만 사용)\")\n",
    "grid_search_lasso.fit(X_train_ins, y_train_ins)  # ← 학습 데이터만!\n",
    "\n",
    "# 최적 alpha\n",
    "best_alpha_lasso = grid_search_lasso.best_params_['alpha']\n",
    "best_mse_cv = -grid_search_lasso.best_score_  # neg를 원래대로\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 문제 3-(4) 결과: 최적 alpha\")\n",
    "print(\"=\"*60)\n",
    "print(f\"최적 alpha: {best_alpha_lasso:.6f}  ← ⭐ 답안!\")\n",
    "print(f\"10-Fold CV MSE: {best_mse_cv:,.2f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 3-(5) Lasso 최종 성과 (MAPE)\n",
    "\n",
    "### 📌 요구사항\n",
    "- 3-(4)에서 찾은 최적 alpha 사용\n",
    "- 학습집합으로 학습\n",
    "- 테스트집합으로 예측\n",
    "- **MAPE로 성과 측정** ← ⭐ MSE에서 MAPE로 변경!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3-(5) 최적 Lasso 모델 성과 측정\n",
    "# ========================================\n",
    "\n",
    "# 최적 모델 가져오기\n",
    "best_lasso = grid_search_lasso.best_estimator_\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "y_pred_test_lasso = best_lasso.predict(X_test_ins)\n",
    "\n",
    "# MAPE 계산 (⭐ 문제에서 요구!)\n",
    "mape_test_lasso = mean_absolute_percentage_error(y_test_ins, y_pred_test_lasso) * 100\n",
    "\n",
    "# 추가 지표\n",
    "mse_test_lasso = mean_squared_error(y_test_ins, y_pred_test_lasso)\n",
    "rmse_test_lasso = np.sqrt(mse_test_lasso)\n",
    "mae_test_lasso = mean_absolute_error(y_test_ins, y_pred_test_lasso)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"📊 문제 3-(5) 결과: Lasso 최종 성과\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n최적 alpha: {best_alpha_lasso:.6f}\")\n",
    "print(f\"\\n[테스트 데이터 성과]  ← ⭐ 답안!\")\n",
    "print(f\"MAPE: {mape_test_lasso:.2f}%  ← ⭐ 문제에서 요구한 지표!\")\n",
    "print(f\"\\n[추가 지표]\")\n",
    "print(f\"MSE:  {mse_test_lasso:,.2f}\")\n",
    "print(f\"RMSE: {rmse_test_lasso:,.2f}\")\n",
    "print(f\"MAE:  {mae_test_lasso:,.2f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Linear Regression vs Lasso 비교\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🏆 모델 비교: Linear Regression vs Lasso\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_df_reg = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Lasso'],\n",
    "    'MAPE (%)': [mape_test, mape_test_lasso],\n",
    "    'RMSE': [rmse_test, rmse_test_lasso],\n",
    "    'MAE': [mae_test, mae_test_lasso]\n",
    "})\n",
    "\n",
    "print(\"\\n\", comparison_df_reg.to_string(index=False))\n",
    "\n",
    "# 더 좋은 모델\n",
    "if mape_test_lasso < mape_test:\n",
    "    print(f\"\\n✅ Lasso가 더 우수 (MAPE 차이: {mape_test - mape_test_lasso:.2f}%p)\")\n",
    "else:\n",
    "    print(f\"\\n✅ Linear Regression이 더 우수 (MAPE 차이: {mape_test_lasso - mape_test:.2f}%p)\")\n",
    "    \n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🎯 최종 정리 및 답안 요약\n",
    "\n",
    "## 문제 1. 로지스틱 회귀 (Phishing)\n",
    "- **(3) 테스트 F1 Score**: 출력된 값 확인\n",
    "- **(4) 5-Fold CV F1 Score 평균**: 출력된 값 확인\n",
    "- **(5) 최적 C 값**: 출력된 값 확인\n",
    "- **(5) 최고 CV ROC AUC**: 출력된 값 확인\n",
    "\n",
    "## 문제 2. 의사결정트리 (Phishing)\n",
    "- **(1) 최대 나무 F1 Score**: 출력된 값 확인\n",
    "- **(2) 최적 max_depth**: 출력된 값 확인\n",
    "- **(2) 최적 모델 F1 Score**: 출력된 값 확인\n",
    "- **(3) 변수 중요도 Top 10**: 테이블 확인\n",
    "\n",
    "## 문제 3. 회귀분석 (Insurance)\n",
    "- **(2) 유의미한 변수**: 회귀계수 테이블의 절대값 큰 변수들\n",
    "- **(3) Linear Regression MAPE**: 출력된 값 확인\n",
    "- **(4) 최적 Lasso alpha**: 출력된 값 확인\n",
    "- **(4) 10-Fold CV MSE**: 출력된 값 확인\n",
    "- **(5) Lasso MAPE**: 출력된 값 확인\n",
    "\n",
    "## 💡 시험 팁\n",
    "1. **⭐ 표시된 부분**이 문제에서 요구한 핵심 답안\n",
    "2. **평가 지표 주의**: F1 Score, ROC AUC, MAPE, MSE 등\n",
    "3. **교차검증 횟수 확인**: 5겹 vs 10겹\n",
    "4. **solver, max_depth 등 특정 파라미터** 요구사항 체크\n",
    "5. 결과 출력 후 **테이블과 그래프**로 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
