{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“ 2024ë…„ ë°ì´í„°ë§ˆì´ë‹ ì¤‘ê°„ê³ ì‚¬ ê¸°ì¶œë¬¸ì œ - ì™„ë²½ ì •ë¦¬ë³¸\n",
    "## â­ ì‹œí—˜ì¥ì—ì„œ ë°”ë¡œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì£¼ì„ ì™„ë¹„!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë¬¸ì œ 1. ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ (Phishing ë¶„ë¥˜) - 40ì \n",
    "\n",
    "## ğŸ¯ ëª©í‘œ: ì›¹ì‚¬ì´íŠ¸ê°€ í”¼ì‹± ì‚¬ì´íŠ¸ì¸ì§€ ë¶„ë¥˜\n",
    "- **ë°ì´í„°**: web-page-phishing.csv\n",
    "- **ëª©í‘œë³€ìˆ˜**: phishing (1: í”¼ì‹±, 0: ì •ìƒ)\n",
    "- **ëª¨ë¸**: ë¡œì§€ìŠ¤í‹± íšŒê·€\n",
    "- **í•µì‹¬ í‰ê°€ì§€í‘œ**: F1 Score, ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ğŸ”¹ ë¶„ë¥˜ ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ë¬¸ì œ 1, 2ìš©)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression  # â† ë¡œì§€ìŠ¤í‹± íšŒê·€\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree  # â† ì˜ì‚¬ê²°ì •íŠ¸ë¦¬\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# ğŸ”¹ íšŒê·€ ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ë¬¸ì œ 3ìš©)\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# dmba ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì‚¬í•­)\n",
    "try:\n",
    "    from dmba import classificationSummary, regressionSummary\n",
    "    HAS_DMBA = True\n",
    "    print(\"âœ… dmba ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê°€ëŠ¥\")\n",
    "except:\n",
    "    HAS_DMBA = False\n",
    "    print(\"âš ï¸ dmba ì—†ìŒ - sklearn metricsë§Œ ì‚¬ìš©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 1-(1) ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "### ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "- ì…ë ¥ë³€ìˆ˜: phishing ì œì™¸í•œ ëª¨ë“  ë³€ìˆ˜\n",
    "- ë°ì´í„° ì „ì²˜ë¦¬ ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1-(1) ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰\n",
    "# ========================================\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv('web-page-phishing.csv')  # â† â­ íŒŒì¼ëª… í™•ì¸!\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š ë°ì´í„° ì •ë³´\")\n",
    "print(\"=\"*60)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ” ê²°ì¸¡ì¹˜ í™•ì¸\")\n",
    "print(\"=\"*60)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‘€ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ)\")\n",
    "print(\"=\"*60)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë³€ìˆ˜ íƒ€ì… ìë™ ë¶„ë¥˜\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ” ë³€ìˆ˜ íƒ€ì… ë¶„ë¥˜\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"\\në²”ì£¼í˜• ë³€ìˆ˜ ({len(categorical_cols)}ê°œ): {categorical_cols}\")\n",
    "print(f\"ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ({len(numerical_cols)}ê°œ): {numerical_cols}\")\n",
    "\n",
    "# ğŸ’¡ ì´ ë°ì´í„°ëŠ” ëª¨ë‘ ìˆ˜ì¹˜í˜•ì¼ ê°€ëŠ¥ì„± ë†’ìŒ (URL íŠ¹ì§•ë“¤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë…ë¦½ë³€ìˆ˜ / ì¢…ì†ë³€ìˆ˜ ë¶„ë¦¬\n",
    "# ========================================\n",
    "\n",
    "# ğŸ¯ ëª©í‘œë³€ìˆ˜ ì„¤ì •\n",
    "outcome = 'phishing'  # â† ë¬¸ì œì—ì„œ ì§€ì •\n",
    "\n",
    "# ğŸ”¹ ë…ë¦½ë³€ìˆ˜ = ëª©í‘œë³€ìˆ˜ ì œì™¸í•œ ëª¨ë“  ë³€ìˆ˜\n",
    "predictors = [col for col in df.columns if col != outcome]\n",
    "\n",
    "X = df[predictors]\n",
    "y = df[outcome]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š ë³€ìˆ˜ ë¶„ë¦¬ ì™„ë£Œ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ë…ë¦½ë³€ìˆ˜ ê°œìˆ˜: {len(predictors)}ê°œ\")\n",
    "print(f\"ë°ì´í„° í¬ê¸°: {X.shape}\")\n",
    "print(f\"\\nëª©í‘œë³€ìˆ˜ ë¶„í¬:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nëª©í‘œë³€ìˆ˜ ë¹„ìœ¨:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "# ğŸ’¡ ì´ì§„ ë¶„ë¥˜ ë¬¸ì œ í™•ì¸!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜ ì›-í•« ì¸ì½”ë”© (í•„ìš”ì‹œ)\n",
    "# ========================================\n",
    "\n",
    "# ì´ ë°ì´í„°ëŠ” ëª¨ë‘ ìˆ˜ì¹˜í˜•ì´ë¼ ì¸ì½”ë”© ë¶ˆí•„ìš”í•  ê°€ëŠ¥ì„± ë†’ìŒ\n",
    "# í•˜ì§€ë§Œ ë²”ì£¼í˜•ì´ ìˆë‹¤ë©´ ì•„ë˜ ì½”ë“œ ì‹¤í–‰\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    print(f\"\\në²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”© ì¤‘: {categorical_cols}\")\n",
    "    X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "    print(f\"ì¸ì½”ë”© í›„ ë³€ìˆ˜ ê°œìˆ˜: {X.shape[1]}ê°œ\")\n",
    "else:\n",
    "    print(\"\\nâœ… ë²”ì£¼í˜• ë³€ìˆ˜ ì—†ìŒ - ì¸ì½”ë”© ë¶ˆí•„ìš”\")\n",
    "\n",
    "print(f\"\\nìµœì¢… ë…ë¦½ë³€ìˆ˜ ê°œìˆ˜: {X.shape[1]}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 1-(2) ë°ì´í„° ë¶„ë¦¬\n",
    "\n",
    "### ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "- ë¬´ì‘ìœ„ ë¶„ë¦¬\n",
    "- **í…ŒìŠ¤íŠ¸ 20%**, í•™ìŠµ 80%\n",
    "- random_state ì„¤ì • (ì¬í˜„ì„±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1-(2) í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• \n",
    "# ========================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # â† â­ ë¬¸ì œì—ì„œ ì§€ì •: í…ŒìŠ¤íŠ¸ 20%\n",
    "    random_state=42,    # â† ì¬í˜„ì„± (ì•„ë¬´ ìˆ«ìë‚˜ ê°€ëŠ¥, 1ë„ ê´œì°®ìŒ)\n",
    "    stratify=y          # â† í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€ (ê¶Œì¥)\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"âœ‚ï¸ ë°ì´í„° ë¶„ë¦¬ ì™„ë£Œ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {X_train.shape} (80%)\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape} (20%)\")\n",
    "print(f\"\\ní•™ìŠµ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\ní…ŒìŠ¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 1-(3) ë¡œì§€ìŠ¤í‹± íšŒê·€ í•™ìŠµ ë° F1 Score ì¸¡ì •\n",
    "\n",
    "### ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "- ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ\n",
    "- í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡\n",
    "- **F1 Scoreë¡œ í‰ê°€** â† â­ í•µì‹¬!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1-(3) ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ (ê¸°ë³¸)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
    "logreg = LogisticRegression(\n",
    "    max_iter=1000,      # â† ìˆ˜ë ´ ë³´ì¥\n",
    "    random_state=42     # â† ì¬í˜„ì„±\n",
    ")\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "# ========================================\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„° ì˜ˆì¸¡\n",
    "y_pred_train = logreg.predict(X_train)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ (â­ ë¬¸ì œì—ì„œ ìš”êµ¬)\n",
    "y_pred_test = logreg.predict(X_test)\n",
    "\n",
    "print(\"âœ… ì˜ˆì¸¡ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# F1 Score ì¸¡ì • (â­ ë¬¸ì œì—ì„œ ìš”êµ¬!)\n",
    "# ========================================\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„° F1 Score\n",
    "f1_train = f1_score(y_train, y_pred_train)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° F1 Score (â­ í•µì‹¬!)\n",
    "f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ë¬¸ì œ 1-(3) ê²°ê³¼: F1 Score\")\n",
    "print(\"=\"*60)\n",
    "print(f\"í•™ìŠµ ë°ì´í„° F1 Score:  {f1_train:.4f}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° F1 Score: {f1_test:.4f}  â† â­ ë‹µì•ˆ!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ì¶”ê°€ ì§€í‘œë“¤ (ì°¸ê³ ìš©)\n",
    "print(f\"\\n[ì¶”ê°€ ì„±ê³¼ ì§€í‘œ - í…ŒìŠ¤íŠ¸ ë°ì´í„°]\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 1-(4) 5ê²¹ êµì°¨ê²€ì¦ (F1 Score)\n",
    "\n",
    "### ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "- **5ê²¹ êµì°¨ê²€ì¦**\n",
    "- **F1 Scoreë¡œ í‰ê°€**\n",
    "- **solver='newton-cholesky'** â† â­ ë¬¸ì œì—ì„œ ì§€ì •!\n",
    "- í‰ê· ì¹˜ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1-(4) 5ê²¹ êµì°¨ê²€ì¦ (F1 Score)\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ”„ 5ê²¹ êµì°¨ê²€ì¦ (solver='newton-cholesky')\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± (â­ solver ì§€ì • í•„ìˆ˜!)\n",
    "logreg_cv = LogisticRegression(\n",
    "    solver='newton-cholesky',  # â† â­ ë¬¸ì œì—ì„œ ì§€ì •!\n",
    "    max_iter=1000,             # â† ìˆ˜ë ´ ë³´ì¥\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 5ê²¹ êµì°¨ê²€ì¦ ìˆ˜í–‰\n",
    "cv_scores = cross_val_score(\n",
    "    logreg_cv, \n",
    "    X_train,        # â† í•™ìŠµ ë°ì´í„°ë§Œ ì‚¬ìš©\n",
    "    y_train, \n",
    "    cv=5,           # â† â­ 5ê²¹\n",
    "    scoring='f1',   # â† â­ F1 Score\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ë¬¸ì œ 1-(4) ê²°ê³¼: 5ê²¹ êµì°¨ê²€ì¦\")\n",
    "print(\"=\"*60)\n",
    "print(f\"5-Fold CV F1 Score: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
    "print(f\"\\nê° Fold ì ìˆ˜: {cv_scores}\")\n",
    "print(f\"\\ní‰ê· : {cv_scores.mean():.4f}  â† â­ ë‹µì•ˆ!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 1-(5) í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (C íŠœë‹)\n",
    "\n",
    "### ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "- **íŒŒë¼ë¯¸í„°**: C (ì •ê·œí™” ê°•ë„ì˜ ì—­ìˆ˜)\n",
    "- **í‰ê°€ ì§€í‘œ**: ROC AUC â† â­ F1ì—ì„œ ë³€ê²½!\n",
    "- **êµì°¨ê²€ì¦**: 10ê²¹ â† â­ 5ê²¹ì—ì„œ ë³€ê²½!\n",
    "- **solver='newton-cholesky'**\n",
    "- ìµœì  C ê°’ ì°¾ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1-(5) C í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (C)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# C ê°’ í›„ë³´ ì •ì˜\n",
    "# Cì˜ default = 1.0\n",
    "# Cê°€ ì‘ì„ìˆ˜ë¡ ê°•í•œ ê·œì œ, í´ìˆ˜ë¡ ì•½í•œ ê·œì œ\n",
    "param_grid = {\n",
    "    'C': np.logspace(-3, 3, 20)  # 0.001 ~ 1000 ì‚¬ì´ 20ê°œ ê°’\n",
    "}\n",
    "\n",
    "# GridSearchCV ì„¤ì •\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(\n",
    "        solver='newton-cholesky',  # â† â­ ë¬¸ì œì—ì„œ ì§€ì •!\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    ),\n",
    "    param_grid,\n",
    "    cv=10,              # â† â­ 10ê²¹ êµì°¨ê²€ì¦\n",
    "    scoring='roc_auc',  # â† â­ ROC AUCë¡œ í‰ê°€\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâ³ GridSearchCV ì§„í–‰ ì¤‘...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ë¬¸ì œ 1-(5) ê²°ê³¼: ìµœì  C ê°’\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ìµœì  C ê°’: {grid_search.best_params_['C']:.6f}  â† â­ ë‹µì•ˆ!\")\n",
    "print(f\"ìµœê³  CV ROC AUC: {grid_search.best_score_:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ìµœì  ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€\n",
    "# ========================================\n",
    "\n",
    "best_logreg = grid_search.best_estimator_\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "y_pred_test_best = best_logreg.predict(X_test)\n",
    "y_pred_proba_test = best_logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ì„±ê³¼ ì¸¡ì •\n",
    "f1_test_best = f1_score(y_test, y_pred_test_best)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ìµœì  ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³¼\")\n",
    "print(\"=\"*60)\n",
    "print(f\"F1 Score:  {f1_test_best:.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_test:.4f}\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_test_best):.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ë¬¸ì œ 2. ì˜ì‚¬ê²°ì •íŠ¸ë¦¬ (Phishing ë¶„ë¥˜) - 20ì \n",
    "\n",
    "## ğŸ¯ ëª©í‘œ: ê°™ì€ ë°ì´í„°ë¡œ ì˜ì‚¬ê²°ì •íŠ¸ë¦¬ ëª¨ë¸ ë§Œë“¤ê¸°\n",
    "- **ë°ì´í„°**: ë¬¸ì œ 1ê³¼ ë™ì¼ (web-page-phishing.csv)\n",
    "- **ëª¨ë¸**: ì˜ì‚¬ê²°ì •íŠ¸ë¦¬\n",
    "- **í•µì‹¬**: max_depth íŠœë‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 2-(1) ìµœëŒ€ ë‚˜ë¬´ ëª¨ë¸ (Full Tree)\n",
    "\n",
    "### ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "- ë¬¸ì œ 1ì˜ ì „ì²˜ë¦¬ëœ í•™ìŠµì§‘í•© ì‚¬ìš©\n",
    "- ìµœëŒ€ ë‚˜ë¬´ (ì œì•½ ì—†ìŒ)\n",
    "- í…ŒìŠ¤íŠ¸ì§‘í•©ìœ¼ë¡œ F1 Score ì¸¡ì •\n",
    "- default ë¶ˆìˆœë„ ì§€í‘œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 2-(1) ìµœëŒ€ ì˜ì‚¬ê²°ì •íŠ¸ë¦¬ ëª¨ë¸\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸŒ³ ì˜ì‚¬ê²°ì •íŠ¸ë¦¬ - ìµœëŒ€ ë‚˜ë¬´ (Full Tree)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± (ì œì•½ ì—†ìŒ)\n",
    "tree_full = DecisionTreeClassifier(\n",
    "    random_state=42  # â† ì¬í˜„ì„±\n",
    "    # criterion='gini'  â† default (ìƒëµ ê°€ëŠ¥)\n",
    "    # max_depth=None    â† default (ìƒëµ ê°€ëŠ¥)\n",
    ")\n",
    "\n",
    "# í•™ìŠµ\n",
    "tree_full.fit(X_train, y_train)\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"\\n[ë‚˜ë¬´ êµ¬ì¡° ì •ë³´]\")\n",
    "print(f\"ìµœëŒ€ ê¹Šì´: {tree_full.get_depth()}\")\n",
    "print(f\"ë¦¬í”„ ë…¸ë“œ ìˆ˜: {tree_full.get_n_leaves()}\")\n",
    "print(f\"ì´ ë…¸ë“œ ìˆ˜: {tree_full.tree_.node_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€ (F1 Score)\n",
    "# ========================================\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y_pred_test_tree = tree_full.predict(X_test)\n",
    "\n",
    "# F1 Score ê³„ì‚°\n",
    "f1_test_tree_full = f1_score(y_test, y_pred_test_tree)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ë¬¸ì œ 2-(1) ê²°ê³¼: ìµœëŒ€ ë‚˜ë¬´ F1 Score\")\n",
    "print(\"=\"*60)\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° F1 Score: {f1_test_tree_full:.4f}  â† â­ ë‹µì•ˆ!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ì¶”ê°€ ì§€í‘œ\n",
    "print(f\"\\n[ì¶”ê°€ ì„±ê³¼ ì§€í‘œ]\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_test_tree):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test_tree):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_test_tree):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 2-(2) max_depth íŠœë‹\n",
    "\n",
    "### ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "- max_depthë¥¼ 2~20ê¹Œì§€ ë³€í™”\n",
    "- ê° depthë§ˆë‹¤ F1 Score ì¸¡ì •\n",
    "- í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì„±ê³¼ ë¹„êµ\n",
    "- ê°€ì¥ ì¢‹ì€ max_depth ì°¾ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 2-(2) max_depth íŠœë‹\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ”§ max_depth íŠœë‹ (2~20)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "depths = range(2, 21)  # 2ë¶€í„° 20ê¹Œì§€\n",
    "train_f1_scores = []\n",
    "test_f1_scores = []\n",
    "\n",
    "for depth in depths:\n",
    "    # ëª¨ë¸ ìƒì„±\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # í•™ìŠµ\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    # í•™ìŠµ ë°ì´í„° F1 Score\n",
    "    train_pred = tree.predict(X_train)\n",
    "    train_f1 = f1_score(y_train, train_pred)\n",
    "    train_f1_scores.append(train_f1)\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„° F1 Score\n",
    "    test_pred = tree.predict(X_test)\n",
    "    test_f1 = f1_score(y_test, test_pred)\n",
    "    test_f1_scores.append(test_f1)\n",
    "\n",
    "# ìµœì  depth ì°¾ê¸°\n",
    "best_depth_idx = np.argmax(test_f1_scores)\n",
    "best_depth = list(depths)[best_depth_idx]\n",
    "best_f1 = test_f1_scores[best_depth_idx]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ë¬¸ì œ 2-(2) ê²°ê³¼: ìµœì  max_depth\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ìµœì  max_depth: {best_depth}  â† â­ ë‹µì•ˆ!\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ F1 Score: {best_f1:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# max_depthë³„ ì„±ê³¼ ì‹œê°í™”\n",
    "# ========================================\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(depths, train_f1_scores, 'o-', label='Train F1', linewidth=2, markersize=6)\n",
    "plt.plot(depths, test_f1_scores, 's-', label='Test F1', linewidth=2, markersize=6)\n",
    "plt.axvline(best_depth, color='r', linestyle='--', linewidth=2, \n",
    "            label=f'Best depth={best_depth}')\n",
    "plt.xlabel('max_depth', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
    "plt.title('F1 Score vs max_depth', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ“Š ê³¼ì í•© ì—¬ë¶€ í™•ì¸:\")\n",
    "print(f\"í•™ìŠµ F1: {train_f1_scores[best_depth_idx]:.4f}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ F1: {test_f1_scores[best_depth_idx]:.4f}\")\n",
    "print(f\"ì°¨ì´: {train_f1_scores[best_depth_idx] - test_f1_scores[best_depth_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 2-(3) ìµœì  ëª¨ë¸ì˜ ë³€ìˆ˜ ì¤‘ìš”ë„\n",
    "\n",
    "### ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "- 2-(2)ì—ì„œ ì°¾ì€ ìµœì  depth ëª¨ë¸ ì‚¬ìš©\n",
    "- ì…ë ¥ ë³€ìˆ˜ ì¤‘ìš”ë„ íŒŒì•…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 2-(3) ë³€ìˆ˜ ì¤‘ìš”ë„ ë¶„ì„\n",
    "# ========================================\n",
    "\n",
    "# ìµœì  depthë¡œ ëª¨ë¸ ì¬í•™ìŠµ\n",
    "tree_best = DecisionTreeClassifier(\n",
    "    max_depth=best_depth,\n",
    "    random_state=42\n",
    ")\n",
    "tree_best.fit(X_train, y_train)\n",
    "\n",
    "# ë³€ìˆ˜ ì¤‘ìš”ë„ ì¶”ì¶œ\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': tree_best.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š ë¬¸ì œ 2-(3) ê²°ê³¼: ë³€ìˆ˜ ì¤‘ìš”ë„\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n[Top 10 ì¤‘ìš” ë³€ìˆ˜]\")\n",
    "print(importance_df.head(10).to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_15 = importance_df.head(15)\n",
    "plt.barh(range(len(top_15)), top_15['importance'])\n",
    "plt.yticks(range(len(top_15)), top_15['feature'])\n",
    "plt.xlabel('Importance', fontsize=12, fontweight='bold')\n",
    "plt.title('Top 15 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ë¬¸ì œ 3. íšŒê·€ë¶„ì„ (Insurance ì²­êµ¬ë¹„ìš© ì˜ˆì¸¡) - 35ì \n",
    "\n",
    "## ğŸ¯ ëª©í‘œ: ë³´í—˜ ì²­êµ¬ë¹„ìš© ì˜ˆì¸¡\n",
    "- **ë°ì´í„°**: insurance.csv\n",
    "- **ëª©í‘œë³€ìˆ˜**: charges (ì²­êµ¬ë¹„ìš©)\n",
    "- **ëª¨ë¸**: Linear Regression, Lasso\n",
    "- **í•µì‹¬ í‰ê°€ì§€í‘œ**: MAPE, MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 3-(1) ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "### ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "- ì¢…ì†ë³€ìˆ˜: charges\n",
    "- ë…ë¦½ë³€ìˆ˜: ë‚˜ë¨¸ì§€ ëª¨ë“  ë³€ìˆ˜\n",
    "- **ë²”ì£¼í˜• ë³€ìˆ˜**: ì›-í•« ì¸ì½”ë”©\n",
    "- **ìˆ˜ì¹˜í˜• ë³€ìˆ˜**: í‘œì¤€í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3-(1) ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰\n",
    "# ========================================\n",
    "\n",
    "df_ins = pd.read_csv('insurance.csv')  # â† â­ íŒŒì¼ëª… í™•ì¸!\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š Insurance ë°ì´í„° ì •ë³´\")\n",
    "print(\"=\"*60)\n",
    "df_ins.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ” ê²°ì¸¡ì¹˜ í™•ì¸\")\n",
    "print(\"=\"*60)\n",
    "print(df_ins.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‘€ ë°ì´í„° ìƒ˜í”Œ\")\n",
    "print(\"=\"*60)\n",
    "print(df_ins.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë³€ìˆ˜ íƒ€ì… ë¶„ë¥˜\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ” ë³€ìˆ˜ íƒ€ì… ë¶„ë¥˜\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "categorical_cols_ins = df_ins.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols_ins = df_ins.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"\\në²”ì£¼í˜• ë³€ìˆ˜: {categorical_cols_ins}\")\n",
    "print(f\"ìˆ˜ì¹˜í˜• ë³€ìˆ˜: {numerical_cols_ins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë…ë¦½ë³€ìˆ˜/ì¢…ì†ë³€ìˆ˜ ë¶„ë¦¬\n",
    "# ========================================\n",
    "\n",
    "outcome_ins = 'charges'  # â† ëª©í‘œë³€ìˆ˜\n",
    "predictors_ins = [col for col in df_ins.columns if col != outcome_ins]\n",
    "\n",
    "X_ins = df_ins[predictors_ins]\n",
    "y_ins = df_ins[outcome_ins]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š ë³€ìˆ˜ ë¶„ë¦¬\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ë…ë¦½ë³€ìˆ˜: {predictors_ins}\")\n",
    "print(f\"ì¢…ì†ë³€ìˆ˜: {outcome_ins}\")\n",
    "print(f\"\\nì¢…ì†ë³€ìˆ˜ ê¸°ë³¸ í†µê³„:\")\n",
    "print(y_ins.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜ ì›-í•« ì¸ì½”ë”©\n",
    "# ========================================\n",
    "\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜ë§Œ ì¸ì½”ë”©\n",
    "categorical_in_X = [col for col in categorical_cols_ins if col in X_ins.columns]\n",
    "\n",
    "if len(categorical_in_X) > 0:\n",
    "    print(f\"\\nì›-í•« ì¸ì½”ë”© ëŒ€ìƒ: {categorical_in_X}\")\n",
    "    X_ins = pd.get_dummies(X_ins, columns=categorical_in_X, drop_first=True)\n",
    "    print(f\"ì¸ì½”ë”© í›„ ë³€ìˆ˜ ê°œìˆ˜: {X_ins.shape[1]}ê°œ\")\n",
    "\n",
    "print(f\"\\nìµœì¢… ë…ë¦½ë³€ìˆ˜ ëª©ë¡: {X_ins.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ í‘œì¤€í™”\n",
    "# ========================================\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì°¾ê¸° (ì›-í•« ì¸ì½”ë”© í›„ ê¸°ì¤€)\n",
    "numerical_in_X = X_ins.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "if len(numerical_in_X) > 0:\n",
    "    scaler_ins = StandardScaler()\n",
    "    X_ins[numerical_in_X] = scaler_ins.fit_transform(X_ins[numerical_in_X])\n",
    "    print(f\"\\nâœ… í‘œì¤€í™” ì™„ë£Œ: {numerical_in_X}\")\n",
    "\n",
    "print(f\"\\nìµœì¢… ë°ì´í„° í¬ê¸°: {X_ins.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 3-(2) íšŒê·€ë¶„ì„ ëª¨í˜• í•™ìŠµ\n",
    "\n",
    "### ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "- ì „ì²´ ë°ì´í„°ë¥¼ **20% í…ŒìŠ¤íŠ¸**, 80% í•™ìŠµìœ¼ë¡œ ë¶„ë¦¬\n",
    "- í•™ìŠµì§‘í•©ìœ¼ë¡œ íšŒê·€ë¶„ì„ ëª¨í˜• í•™ìŠµ\n",
    "- ì²­êµ¬ë¹„ìš©ì— ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë³€ìˆ˜ íŒŒì•…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3-(2) ë°ì´í„° ë¶„ë¦¬\n",
    "# ========================================\n",
    "\n",
    "X_train_ins, X_test_ins, y_train_ins, y_test_ins = train_test_split(\n",
    "    X_ins, y_ins,\n",
    "    test_size=0.2,     # â† â­ í…ŒìŠ¤íŠ¸ 20%\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"âœ‚ï¸ ë°ì´í„° ë¶„ë¦¬\")\n",
    "print(\"=\"*60)\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {X_train_ins.shape} (80%)\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test_ins.shape} (20%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# íšŒê·€ë¶„ì„ ëª¨í˜• í•™ìŠµ\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š Linear Regression í•™ìŠµ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lr_ins = LinearRegression()\n",
    "lr_ins.fit(X_train_ins, y_train_ins)\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# íšŒê·€ê³„ìˆ˜ í™•ì¸ (ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ íŒŒì•…)\n",
    "# ========================================\n",
    "\n",
    "coef_df_ins = pd.DataFrame({\n",
    "    'Variable': X_train_ins.columns,\n",
    "    'Coefficient': lr_ins.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ë¬¸ì œ 3-(2) ê²°ê³¼: íšŒê·€ê³„ìˆ˜\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ì ˆí¸(Intercept): {lr_ins.intercept_:.4f}\")\n",
    "print(f\"\\níšŒê·€ê³„ìˆ˜ (ì ˆëŒ€ê°’ ê¸°ì¤€ ì •ë ¬):\")\n",
    "print(coef_df_ins.to_string(index=False))\n",
    "print(\"\\nğŸ’¡ ê³„ìˆ˜ì˜ ì ˆëŒ€ê°’ì´ í´ìˆ˜ë¡ ì˜í–¥ë ¥ì´ í¼!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 3-(3) íšŒê·€ë¶„ì„ ì„±ê³¼ ì¸¡ì • (MAPE)\n",
    "\n",
    "### ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "- í…ŒìŠ¤íŠ¸ì§‘í•©ìœ¼ë¡œ ì˜ˆì¸¡\n",
    "- **MAPEë¡œ ì„±ê³¼ ì¸¡ì •** â† â­ í•µì‹¬!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3-(3) ì˜ˆì¸¡ ë° MAPE ì¸¡ì •\n",
    "# ========================================\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y_pred_train_ins = lr_ins.predict(X_train_ins)\n",
    "y_pred_test_ins = lr_ins.predict(X_test_ins)\n",
    "\n",
    "# MAPE ê³„ì‚° (â­ ë¬¸ì œì—ì„œ ìš”êµ¬!)\n",
    "mape_train = mean_absolute_percentage_error(y_train_ins, y_pred_train_ins) * 100\n",
    "mape_test = mean_absolute_percentage_error(y_test_ins, y_pred_test_ins) * 100\n",
    "\n",
    "# ì¶”ê°€ ì§€í‘œë“¤\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_ins, y_pred_test_ins))\n",
    "mae_test = mean_absolute_error(y_test_ins, y_pred_test_ins)\n",
    "r2_test = lr_ins.score(X_test_ins, y_test_ins)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š ë¬¸ì œ 3-(3) ê²°ê³¼: íšŒê·€ë¶„ì„ ì„±ê³¼\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n[í•™ìŠµ ë°ì´í„°]\")\n",
    "print(f\"MAPE: {mape_train:.2f}%\")\n",
    "\n",
    "print(f\"\\n[í…ŒìŠ¤íŠ¸ ë°ì´í„°]  â† â­ ë‹µì•ˆ!\")\n",
    "print(f\"MAPE: {mape_test:.2f}%  â† â­ ë¬¸ì œì—ì„œ ìš”êµ¬í•œ ì§€í‘œ!\")\n",
    "print(f\"\\n[ì¶”ê°€ ì§€í‘œ]\")\n",
    "print(f\"RMSE: {rmse_test:,.2f}\")\n",
    "print(f\"MAE:  {mae_test:,.2f}\")\n",
    "print(f\"RÂ²:   {r2_test:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 3-(4) Lasso í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "\n",
    "### ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "- **í•™ìŠµì§‘í•©ë§Œ** ì‚¬ìš© (í…ŒìŠ¤íŠ¸ì§‘í•© ì‚¬ìš© X)\n",
    "- alpha íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "- **10ê²¹ êµì°¨ê²€ì¦**\n",
    "- **MSEë¡œ í‰ê°€** â† â­ scoring='neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3-(4) Lasso alpha íŠœë‹\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ”§ Lasso í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (alpha)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# alpha í›„ë³´ ì •ì˜\n",
    "param_grid_lasso = {\n",
    "    'alpha': np.logspace(-4, 2, 100)  # 0.0001 ~ 100 ì‚¬ì´ 100ê°œ ê°’\n",
    "}\n",
    "\n",
    "# GridSearchCV ì„¤ì •\n",
    "grid_search_lasso = GridSearchCV(\n",
    "    Lasso(max_iter=10000, random_state=42),\n",
    "    param_grid_lasso,\n",
    "    cv=10,                          # â† â­ 10ê²¹ êµì°¨ê²€ì¦\n",
    "    scoring='neg_mean_squared_error',  # â† â­ MSEë¡œ í‰ê°€\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâ³ GridSearchCV ì§„í–‰ ì¤‘... (í•™ìŠµ ë°ì´í„°ë§Œ ì‚¬ìš©)\")\n",
    "grid_search_lasso.fit(X_train_ins, y_train_ins)  # â† í•™ìŠµ ë°ì´í„°ë§Œ!\n",
    "\n",
    "# ìµœì  alpha\n",
    "best_alpha_lasso = grid_search_lasso.best_params_['alpha']\n",
    "best_mse_cv = -grid_search_lasso.best_score_  # negë¥¼ ì›ë˜ëŒ€ë¡œ\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ë¬¸ì œ 3-(4) ê²°ê³¼: ìµœì  alpha\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ìµœì  alpha: {best_alpha_lasso:.6f}  â† â­ ë‹µì•ˆ!\")\n",
    "print(f\"10-Fold CV MSE: {best_mse_cv:,.2f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 3-(5) Lasso ìµœì¢… ì„±ê³¼ (MAPE)\n",
    "\n",
    "### ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "- 3-(4)ì—ì„œ ì°¾ì€ ìµœì  alpha ì‚¬ìš©\n",
    "- í•™ìŠµì§‘í•©ìœ¼ë¡œ í•™ìŠµ\n",
    "- í…ŒìŠ¤íŠ¸ì§‘í•©ìœ¼ë¡œ ì˜ˆì¸¡\n",
    "- **MAPEë¡œ ì„±ê³¼ ì¸¡ì •** â† â­ MSEì—ì„œ MAPEë¡œ ë³€ê²½!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3-(5) ìµœì  Lasso ëª¨ë¸ ì„±ê³¼ ì¸¡ì •\n",
    "# ========================================\n",
    "\n",
    "# ìµœì  ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°\n",
    "best_lasso = grid_search_lasso.best_estimator_\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "y_pred_test_lasso = best_lasso.predict(X_test_ins)\n",
    "\n",
    "# MAPE ê³„ì‚° (â­ ë¬¸ì œì—ì„œ ìš”êµ¬!)\n",
    "mape_test_lasso = mean_absolute_percentage_error(y_test_ins, y_pred_test_lasso) * 100\n",
    "\n",
    "# ì¶”ê°€ ì§€í‘œ\n",
    "mse_test_lasso = mean_squared_error(y_test_ins, y_pred_test_lasso)\n",
    "rmse_test_lasso = np.sqrt(mse_test_lasso)\n",
    "mae_test_lasso = mean_absolute_error(y_test_ins, y_pred_test_lasso)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š ë¬¸ì œ 3-(5) ê²°ê³¼: Lasso ìµœì¢… ì„±ê³¼\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nìµœì  alpha: {best_alpha_lasso:.6f}\")\n",
    "print(f\"\\n[í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„±ê³¼]  â† â­ ë‹µì•ˆ!\")\n",
    "print(f\"MAPE: {mape_test_lasso:.2f}%  â† â­ ë¬¸ì œì—ì„œ ìš”êµ¬í•œ ì§€í‘œ!\")\n",
    "print(f\"\\n[ì¶”ê°€ ì§€í‘œ]\")\n",
    "print(f\"MSE:  {mse_test_lasso:,.2f}\")\n",
    "print(f\"RMSE: {rmse_test_lasso:,.2f}\")\n",
    "print(f\"MAE:  {mae_test_lasso:,.2f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Linear Regression vs Lasso ë¹„êµ\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ† ëª¨ë¸ ë¹„êµ: Linear Regression vs Lasso\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_df_reg = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Lasso'],\n",
    "    'MAPE (%)': [mape_test, mape_test_lasso],\n",
    "    'RMSE': [rmse_test, rmse_test_lasso],\n",
    "    'MAE': [mae_test, mae_test_lasso]\n",
    "})\n",
    "\n",
    "print(\"\\n\", comparison_df_reg.to_string(index=False))\n",
    "\n",
    "# ë” ì¢‹ì€ ëª¨ë¸\n",
    "if mape_test_lasso < mape_test:\n",
    "    print(f\"\\nâœ… Lassoê°€ ë” ìš°ìˆ˜ (MAPE ì°¨ì´: {mape_test - mape_test_lasso:.2f}%p)\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Linear Regressionì´ ë” ìš°ìˆ˜ (MAPE ì°¨ì´: {mape_test_lasso - mape_test:.2f}%p)\")\n",
    "    \n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ¯ ìµœì¢… ì •ë¦¬ ë° ë‹µì•ˆ ìš”ì•½\n",
    "\n",
    "## ë¬¸ì œ 1. ë¡œì§€ìŠ¤í‹± íšŒê·€ (Phishing)\n",
    "- **(3) í…ŒìŠ¤íŠ¸ F1 Score**: ì¶œë ¥ëœ ê°’ í™•ì¸\n",
    "- **(4) 5-Fold CV F1 Score í‰ê· **: ì¶œë ¥ëœ ê°’ í™•ì¸\n",
    "- **(5) ìµœì  C ê°’**: ì¶œë ¥ëœ ê°’ í™•ì¸\n",
    "- **(5) ìµœê³  CV ROC AUC**: ì¶œë ¥ëœ ê°’ í™•ì¸\n",
    "\n",
    "## ë¬¸ì œ 2. ì˜ì‚¬ê²°ì •íŠ¸ë¦¬ (Phishing)\n",
    "- **(1) ìµœëŒ€ ë‚˜ë¬´ F1 Score**: ì¶œë ¥ëœ ê°’ í™•ì¸\n",
    "- **(2) ìµœì  max_depth**: ì¶œë ¥ëœ ê°’ í™•ì¸\n",
    "- **(2) ìµœì  ëª¨ë¸ F1 Score**: ì¶œë ¥ëœ ê°’ í™•ì¸\n",
    "- **(3) ë³€ìˆ˜ ì¤‘ìš”ë„ Top 10**: í…Œì´ë¸” í™•ì¸\n",
    "\n",
    "## ë¬¸ì œ 3. íšŒê·€ë¶„ì„ (Insurance)\n",
    "- **(2) ìœ ì˜ë¯¸í•œ ë³€ìˆ˜**: íšŒê·€ê³„ìˆ˜ í…Œì´ë¸”ì˜ ì ˆëŒ€ê°’ í° ë³€ìˆ˜ë“¤\n",
    "- **(3) Linear Regression MAPE**: ì¶œë ¥ëœ ê°’ í™•ì¸\n",
    "- **(4) ìµœì  Lasso alpha**: ì¶œë ¥ëœ ê°’ í™•ì¸\n",
    "- **(4) 10-Fold CV MSE**: ì¶œë ¥ëœ ê°’ í™•ì¸\n",
    "- **(5) Lasso MAPE**: ì¶œë ¥ëœ ê°’ í™•ì¸\n",
    "\n",
    "## ğŸ’¡ ì‹œí—˜ íŒ\n",
    "1. **â­ í‘œì‹œëœ ë¶€ë¶„**ì´ ë¬¸ì œì—ì„œ ìš”êµ¬í•œ í•µì‹¬ ë‹µì•ˆ\n",
    "2. **í‰ê°€ ì§€í‘œ ì£¼ì˜**: F1 Score, ROC AUC, MAPE, MSE ë“±\n",
    "3. **êµì°¨ê²€ì¦ íšŸìˆ˜ í™•ì¸**: 5ê²¹ vs 10ê²¹\n",
    "4. **solver, max_depth ë“± íŠ¹ì • íŒŒë¼ë¯¸í„°** ìš”êµ¬ì‚¬í•­ ì²´í¬\n",
    "5. ê²°ê³¼ ì¶œë ¥ í›„ **í…Œì´ë¸”ê³¼ ê·¸ë˜í”„**ë¡œ í™•ì¸"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
