{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ì™„ë²½ í”„ë ˆì„ - ì‹œí—˜ìš© v2 ğŸ“Š\n",
    "## ëª¨ë“  ê¸°ì¶œ ìœ í˜• ëŒ€ì‘ ê°€ëŠ¥! (F1 Score, ROC AUC, Accuracy ëª¨ë‘ í¬í•¨)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# dmba ë¼ì´ë¸ŒëŸ¬ë¦¬ (ìˆìœ¼ë©´)\n",
    "try:\n",
    "    from dmba import classificationSummary\n",
    "    HAS_DMBA = True\n",
    "except:\n",
    "    HAS_DMBA = False\n",
    "    print(\"dmba ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì§€í‘œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ (â­ íŒŒì¼ëª… ìˆ˜ì • í•„ìˆ˜!)\n",
    "df = pd.read_csv('ë°ì´í„°íŒŒì¼.csv')\n",
    "\n",
    "print(\"[ë°ì´í„° ì •ë³´]\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n[ê²°ì¸¡ì¹˜ í™•ì¸]\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n[ë°ì´í„° ìƒ˜í”Œ]\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³€ìˆ˜ íƒ€ì… ìë™ ë¶„ë¥˜\n",
    "print(\"[ë³€ìˆ˜ íƒ€ì… ë¶„ë¥˜]\")\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"ë²”ì£¼í˜• ë³€ìˆ˜ ({len(categorical_cols)}ê°œ): {categorical_cols}\")\n",
    "print(f\"ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ({len(numerical_cols)}ê°œ): {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª©í‘œë³€ìˆ˜ë¥¼ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜ (í•„ìš”ì‹œ)\n",
    "# df['ëª©í‘œë³€ìˆ˜'] = df['ëª©í‘œë³€ìˆ˜'].astype('category')\n",
    "\n",
    "# ë…ë¦½ë³€ìˆ˜/ì¢…ì†ë³€ìˆ˜ ë¶„ë¦¬ (â­ ì—¬ê¸° ìˆ˜ì • í•„ìˆ˜!)\n",
    "outcome = 'ëª©í‘œë³€ìˆ˜'  # â† ì¢…ì†ë³€ìˆ˜ ì´ë¦„ ì…ë ¥\n",
    "predictors = [col for col in df.columns \n",
    "              if col not in [outcome, 'ì œì™¸í• ë³€ìˆ˜1', 'ì œì™¸í• ë³€ìˆ˜2']]\n",
    "\n",
    "X = df[predictors]\n",
    "y = df[outcome]\n",
    "\n",
    "print(f\"ë…ë¦½ë³€ìˆ˜ ê°œìˆ˜: {len(predictors)}\")\n",
    "print(f\"ë°ì´í„° í¬ê¸°: {X.shape}\")\n",
    "print(f\"\\nëª©í‘œë³€ìˆ˜ ë¶„í¬:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ì¢…ë¥˜ë³„ ì „ì²˜ë¦¬ ë°©ë²•\n",
    "print(\"\\n[ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ 3ê°€ì§€ ìœ í˜•]\")\n",
    "print(\"1. MultinomialNB: ì¹´ìš´íŠ¸/ë¹ˆë„ ë°ì´í„° (ìŒìˆ˜ ë¶ˆê°€, ì •ìˆ˜ ì¶”ì²œ)\")\n",
    "print(\"2. GaussianNB: ì—°ì†í˜• ë°ì´í„° (ì •ê·œë¶„í¬ ê°€ì •)\")\n",
    "print(\"3. BernoulliNB: ì´ì§„ ë°ì´í„° (0/1)\")\n",
    "print(\"\\nâ­ ë°ì´í„° íŠ¹ì„±ì— ë§ê²Œ ëª¨ë¸ ì„ íƒ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì „ì²˜ë¦¬ - MultinomialNBìš© (ì¹´ìš´íŠ¸/ë¹ˆë„ ë°ì´í„°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNBëŠ” ìŒìˆ˜ ê°’ì„ í—ˆìš©í•˜ì§€ ì•ŠìŒ\n",
    "# ë°©ë²• 1: ì›-í•« ì¸ì½”ë”© (drop_first=False ê¶Œì¥)\n",
    "X_multi = pd.get_dummies(X, drop_first=False)\n",
    "\n",
    "# ë°©ë²• 2: ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ ìŒìˆ˜ë©´ MinMaxScaler ì‚¬ìš©\n",
    "# scaler = MinMaxScaler()\n",
    "# X_multi[numerical_cols] = scaler.fit_transform(X_multi[numerical_cols])\n",
    "\n",
    "print(f\"MultinomialNBìš© ë³€ìˆ˜ ê°œìˆ˜: {X_multi.shape[1]}\")\n",
    "print(f\"ë³€ìˆ˜ ëª©ë¡ (ì²˜ìŒ 10ê°œ): {X_multi.columns.tolist()[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì „ì²˜ë¦¬ - GaussianNBìš© (ì—°ì†í˜• ë°ì´í„°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GaussianNBëŠ” í‘œì¤€í™” ê¶Œì¥ (ì„ íƒì‚¬í•­)\n",
    "X_gauss = pd.get_dummies(X, drop_first=False)\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ í‘œì¤€í™”\n",
    "numerical_features = X_gauss.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "if len(numerical_features) > 0:\n",
    "    scaler = StandardScaler()\n",
    "    X_gauss[numerical_features] = scaler.fit_transform(X_gauss[numerical_features])\n",
    "    print(f\"í‘œì¤€í™”ëœ ìˆ˜ì¹˜í˜• ë³€ìˆ˜: {len(numerical_features)}ê°œ\")\n",
    "\n",
    "print(f\"GaussianNBìš© ë³€ìˆ˜ ê°œìˆ˜: {X_gauss.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ë°ì´í„° ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°©ë²• 1: train_test_split ì‚¬ìš© (ì¼ë°˜ì )\n",
    "# MultinomialNBìš©\n",
    "train_X_multi, valid_X_multi, train_y, valid_y = train_test_split(\n",
    "    X_multi, y, test_size=0.3, random_state=1, stratify=y\n",
    ")\n",
    "\n",
    "# GaussianNBìš© (ê°™ì€ ë¶„í•  ì‚¬ìš©)\n",
    "train_X_gauss, valid_X_gauss = X_gauss.iloc[train_X_multi.index], X_gauss.iloc[valid_X_multi.index]\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {train_X_multi.shape}\")\n",
    "print(f\"ê²€ì¦ ë°ì´í„°: {valid_X_multi.shape}\")\n",
    "print(f\"\\ní•™ìŠµ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:\\n{train_y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°©ë²• 2: ì¸ë±ìŠ¤ ê¸°ë°˜ ë¶„ë¦¬ (ê¸°ì¶œë¬¸ì œ ìŠ¤íƒ€ì¼)\n",
    "# ì˜ˆ: \"0~1999ë²ˆê¹Œì§€ í•™ìŠµ, 2000ë²ˆ~ í…ŒìŠ¤íŠ¸\"\n",
    "\n",
    "# train_X_multi = X_multi.iloc[:2000]\n",
    "# train_X_gauss = X_gauss.iloc[:2000]\n",
    "# train_y = y.iloc[:2000]\n",
    "# valid_X_multi = X_multi.iloc[2000:]\n",
    "# valid_X_gauss = X_gauss.iloc[2000:]\n",
    "# valid_y = y.iloc[2000:]\n",
    "\n",
    "# print(f\"í•™ìŠµ ë°ì´í„°: {train_X_multi.shape}\")\n",
    "# print(f\"ê²€ì¦ ë°ì´í„°: {valid_X_multi.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MultinomialNB - ê¸°ë³¸ ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"MultinomialNB - ê¸°ë³¸ ëª¨ë¸ (alpha=1.0)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± (alphaëŠ” ë¼í”Œë¼ìŠ¤ ìŠ¤ë¬´ë”©)\n",
    "nb_multi = MultinomialNB(alpha=1.0)\n",
    "nb_multi.fit(train_X_multi, train_y)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred_train_y = nb_multi.predict(train_X_multi)\n",
    "pred_valid_y = nb_multi.predict(valid_X_multi)\n",
    "\n",
    "# ì„±ê³¼ ì¸¡ì •\n",
    "print(\"\\n[í•™ìŠµ ë°ì´í„° ì„±ê³¼]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(train_y, pred_train_y, class_names=nb_multi.classes_)\n",
    "else:\n",
    "    print(f\"Accuracy:  {accuracy_score(train_y, pred_train_y):.4f}\")\n",
    "    print(f\"Precision: {precision_score(train_y, pred_train_y, average='weighted'):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(train_y, pred_train_y, average='weighted'):.4f}\")\n",
    "    print(f\"F1-Score:  {f1_score(train_y, pred_train_y, average='weighted'):.4f}\")\n",
    "\n",
    "print(\"\\n[ê²€ì¦ ë°ì´í„° ì„±ê³¼]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(valid_y, pred_valid_y, class_names=nb_multi.classes_)\n",
    "else:\n",
    "    print(f\"Accuracy:  {accuracy_score(valid_y, pred_valid_y):.4f}\")\n",
    "    print(f\"Precision: {precision_score(valid_y, pred_valid_y, average='weighted'):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(valid_y, pred_valid_y, average='weighted'):.4f}\")\n",
    "    print(f\"F1-Score:  {f1_score(valid_y, pred_valid_y, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ ê¸°ì¶œ ëŒ€ì‘: ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œë¡œ êµì°¨ê²€ì¦\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š 5-Fold êµì°¨ê²€ì¦ (ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œ)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Accuracy\n",
    "scores_acc = cross_val_score(nb_multi, X_multi, y, cv=5, scoring='accuracy')\n",
    "print(f\"\\nâœ… 5-Fold CV Accuracy: {scores_acc.mean():.4f} (Â±{scores_acc.std():.4f})\")\n",
    "\n",
    "# F1 Score (ê¸°ì¶œì— ìì£¼ ë‚˜ì˜´!)\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_f1 = cross_val_score(nb_multi, X_multi, y, cv=5, scoring='f1')\n",
    "    print(f\"âœ… 5-Fold CV F1 Score: {scores_f1.mean():.4f} (Â±{scores_f1.std():.4f})\")\n",
    "else:\n",
    "    scores_f1 = cross_val_score(nb_multi, X_multi, y, cv=5, scoring='f1_weighted')\n",
    "    print(f\"âœ… 5-Fold CV F1 Score (weighted): {scores_f1.mean():.4f} (Â±{scores_f1.std():.4f})\")\n",
    "\n",
    "# ROC AUC (ì´ì§„ ë¶„ë¥˜ì¸ ê²½ìš°)\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_auc = cross_val_score(nb_multi, X_multi, y, cv=5, scoring='roc_auc')\n",
    "    print(f\"âœ… 5-Fold CV ROC AUC: {scores_auc.mean():.4f} (Â±{scores_auc.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. GaussianNB - ê¸°ë³¸ ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"GaussianNB - ê¸°ë³¸ ëª¨ë¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "nb_gauss = GaussianNB()\n",
    "nb_gauss.fit(train_X_gauss, train_y)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred_train_y = nb_gauss.predict(train_X_gauss)\n",
    "pred_valid_y = nb_gauss.predict(valid_X_gauss)\n",
    "\n",
    "# ì„±ê³¼ ì¸¡ì •\n",
    "print(\"\\n[í•™ìŠµ ë°ì´í„° ì„±ê³¼]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(train_y, pred_train_y, class_names=nb_gauss.classes_)\n",
    "else:\n",
    "    print(f\"Accuracy:  {accuracy_score(train_y, pred_train_y):.4f}\")\n",
    "    print(f\"Precision: {precision_score(train_y, pred_train_y, average='weighted'):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(train_y, pred_train_y, average='weighted'):.4f}\")\n",
    "    print(f\"F1-Score:  {f1_score(train_y, pred_train_y, average='weighted'):.4f}\")\n",
    "\n",
    "print(\"\\n[ê²€ì¦ ë°ì´í„° ì„±ê³¼]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(valid_y, pred_valid_y, class_names=nb_gauss.classes_)\n",
    "else:\n",
    "    print(f\"Accuracy:  {accuracy_score(valid_y, pred_valid_y):.4f}\")\n",
    "    print(f\"Precision: {precision_score(valid_y, pred_valid_y, average='weighted'):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(valid_y, pred_valid_y, average='weighted'):.4f}\")\n",
    "    print(f\"F1-Score:  {f1_score(valid_y, pred_valid_y, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ ê¸°ì¶œ ëŒ€ì‘: ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œë¡œ êµì°¨ê²€ì¦\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š 5-Fold êµì°¨ê²€ì¦ (ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œ)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Accuracy\n",
    "scores_acc = cross_val_score(nb_gauss, X_gauss, y, cv=5, scoring='accuracy')\n",
    "print(f\"\\nâœ… 5-Fold CV Accuracy: {scores_acc.mean():.4f} (Â±{scores_acc.std():.4f})\")\n",
    "\n",
    "# F1 Score\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_f1_gauss = cross_val_score(nb_gauss, X_gauss, y, cv=5, scoring='f1')\n",
    "    print(f\"âœ… 5-Fold CV F1 Score: {scores_f1_gauss.mean():.4f} (Â±{scores_f1_gauss.std():.4f})\")\n",
    "else:\n",
    "    scores_f1_gauss = cross_val_score(nb_gauss, X_gauss, y, cv=5, scoring='f1_weighted')\n",
    "    print(f\"âœ… 5-Fold CV F1 Score (weighted): {scores_f1_gauss.mean():.4f} (Â±{scores_f1_gauss.std():.4f})\")\n",
    "\n",
    "# ROC AUC (ì´ì§„ ë¶„ë¥˜ì¸ ê²½ìš°)\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_auc_gauss = cross_val_score(nb_gauss, X_gauss, y, cv=5, scoring='roc_auc')\n",
    "    print(f\"âœ… 5-Fold CV ROC AUC: {scores_auc_gauss.mean():.4f} (Â±{scores_auc_gauss.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. MultinomialNB alpha íŠœë‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha ê°’ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”\n",
    "alphas = [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "train_scores = []\n",
    "valid_scores = []\n",
    "cv_scores = []\n",
    "\n",
    "# ê¸°ì¶œì—ì„œ ìì£¼ ì“°ëŠ” ì§€í‘œ ì„ íƒ (F1 Score ë˜ëŠ” ROC AUC)\n",
    "if len(np.unique(y)) == 2:\n",
    "    scoring = 'f1'  # ì´ì§„ ë¶„ë¥˜: F1 Score\n",
    "    metric_name = 'F1 Score'\n",
    "else:\n",
    "    scoring = 'f1_weighted'  # ë‹¤ì¤‘ ë¶„ë¥˜: F1 Score (weighted)\n",
    "    metric_name = 'F1 Score (weighted)'\n",
    "\n",
    "for alpha in alphas:\n",
    "    nb = MultinomialNB(alpha=alpha)\n",
    "    nb.fit(train_X_multi, train_y)\n",
    "    \n",
    "    # í•™ìŠµ/ê²€ì¦ ë°ì´í„° ì ìˆ˜\n",
    "    train_scores.append(f1_score(train_y, nb.predict(train_X_multi), average='weighted' if len(np.unique(y)) > 2 else 'binary'))\n",
    "    valid_scores.append(f1_score(valid_y, nb.predict(valid_X_multi), average='weighted' if len(np.unique(y)) > 2 else 'binary'))\n",
    "    \n",
    "    # êµì°¨ê²€ì¦\n",
    "    scores = cross_val_score(nb, X_multi, y, cv=5, scoring=scoring)\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# ìµœì  alpha ì°¾ê¸°\n",
    "best_alpha_idx = np.argmax(cv_scores)\n",
    "best_alpha = alphas[best_alpha_idx]\n",
    "best_score = cv_scores[best_alpha_idx]\n",
    "\n",
    "print(f\"\\nìµœì  alpha: {best_alpha}\")\n",
    "print(f\"ìµœê³  CV {metric_name}: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(alphas, train_scores, 'o-', label='Train', linewidth=2)\n",
    "plt.plot(alphas, valid_scores, 's-', label='Valid', linewidth=2)\n",
    "plt.plot(alphas, cv_scores, '^-', label='5-Fold CV', linewidth=2)\n",
    "plt.axvline(best_alpha, color='r', linestyle='--', label=f'Best alpha={best_alpha}')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('alpha (Smoothing Parameter)', fontsize=12)\n",
    "plt.ylabel(metric_name, fontsize=12)\n",
    "plt.title('MultinomialNB Performance vs alpha', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ìµœì  MultinomialNB ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(f\"ìµœì  MultinomialNB (alpha={best_alpha})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "nb_multi_best = MultinomialNB(alpha=best_alpha)\n",
    "nb_multi_best.fit(train_X_multi, train_y)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred_train_y = nb_multi_best.predict(train_X_multi)\n",
    "pred_valid_y = nb_multi_best.predict(valid_X_multi)\n",
    "\n",
    "print(\"\\n[í•™ìŠµ ë°ì´í„° ì„±ê³¼]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(train_y, pred_train_y, class_names=nb_multi_best.classes_)\n",
    "else:\n",
    "    print(f\"Accuracy:  {accuracy_score(train_y, pred_train_y):.4f}\")\n",
    "    print(f\"F1-Score:  {f1_score(train_y, pred_train_y, average='weighted' if len(np.unique(y)) > 2 else 'binary'):.4f}\")\n",
    "\n",
    "print(\"\\n[ê²€ì¦ ë°ì´í„° ì„±ê³¼]\")\n",
    "if HAS_DMBA:\n",
    "    classificationSummary(valid_y, pred_valid_y, class_names=nb_multi_best.classes_)\n",
    "else:\n",
    "    print(f\"Accuracy:  {accuracy_score(valid_y, pred_valid_y):.4f}\")\n",
    "    print(f\"F1-Score:  {f1_score(valid_y, pred_valid_y, average='weighted' if len(np.unique(y)) > 2 else 'binary'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ ê¸°ì¶œ ëŒ€ì‘: ëª¨ë“  ì£¼ìš” ì§€í‘œ ì¶œë ¥\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ìµœì  ëª¨ë¸ êµì°¨ê²€ì¦ ì„±ê³¼ (ëª¨ë“  ì§€í‘œ)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Accuracy\n",
    "scores_acc_best = cross_val_score(nb_multi_best, X_multi, y, cv=5, scoring='accuracy')\n",
    "print(f\"\\nâœ… 5-Fold CV Accuracy: {scores_acc_best.mean():.4f} (Â±{scores_acc_best.std():.4f})\")\n",
    "\n",
    "# F1 Score\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_f1_best = cross_val_score(nb_multi_best, X_multi, y, cv=5, scoring='f1')\n",
    "    print(f\"âœ… 5-Fold CV F1 Score: {scores_f1_best.mean():.4f} (Â±{scores_f1_best.std():.4f})\")\n",
    "else:\n",
    "    scores_f1_best = cross_val_score(nb_multi_best, X_multi, y, cv=5, scoring='f1_weighted')\n",
    "    print(f\"âœ… 5-Fold CV F1 Score (weighted): {scores_f1_best.mean():.4f} (Â±{scores_f1_best.std():.4f})\")\n",
    "\n",
    "# ROC AUC (ì´ì§„ ë¶„ë¥˜)\n",
    "if len(np.unique(y)) == 2:\n",
    "    scores_auc_best = cross_val_score(nb_multi_best, X_multi, y, cv=5, scoring='roc_auc')\n",
    "    print(f\"âœ… 5-Fold CV ROC AUC: {scores_auc_best.mean():.4f} (Â±{scores_auc_best.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ëª¨ë¸ ë¹„êµ - MultinomialNB vs GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ğŸ† ëª¨ë¸ ë¹„êµ: MultinomialNB vs GaussianNB\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# MultinomialNB\n",
    "multi_acc = accuracy_score(valid_y, nb_multi_best.predict(valid_X_multi))\n",
    "multi_f1 = f1_score(valid_y, nb_multi_best.predict(valid_X_multi), average='weighted' if len(np.unique(y)) > 2 else 'binary')\n",
    "multi_cv_acc = scores_acc_best.mean()\n",
    "multi_cv_f1 = scores_f1_best.mean()\n",
    "\n",
    "# GaussianNB  \n",
    "gauss_acc = accuracy_score(valid_y, nb_gauss.predict(valid_X_gauss))\n",
    "gauss_f1 = f1_score(valid_y, nb_gauss.predict(valid_X_gauss), average='weighted' if len(np.unique(y)) > 2 else 'binary')\n",
    "gauss_cv_acc = scores_acc.mean()\n",
    "gauss_cv_f1 = scores_f1_gauss.mean()\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['MultinomialNB', 'GaussianNB'],\n",
    "    'Valid Accuracy': [multi_acc, gauss_acc],\n",
    "    'Valid F1 Score': [multi_f1, gauss_f1],\n",
    "    '5-Fold CV Accuracy': [multi_cv_acc, gauss_cv_acc],\n",
    "    '5-Fold CV F1 Score': [multi_cv_f1, gauss_cv_f1]\n",
    "})\n",
    "\n",
    "# ROC AUC ì¶”ê°€ (ì´ì§„ ë¶„ë¥˜ì¸ ê²½ìš°)\n",
    "if len(np.unique(y)) == 2:\n",
    "    multi_auc = roc_auc_score(valid_y, nb_multi_best.predict_proba(valid_X_multi)[:, 1])\n",
    "    gauss_auc = roc_auc_score(valid_y, nb_gauss.predict_proba(valid_X_gauss)[:, 1])\n",
    "    multi_cv_auc = scores_auc_best.mean()\n",
    "    gauss_cv_auc = scores_auc_gauss.mean()\n",
    "    \n",
    "    comparison_df['Valid ROC AUC'] = [multi_auc, gauss_auc]\n",
    "    comparison_df['5-Fold CV ROC AUC'] = [multi_cv_auc, gauss_cv_auc]\n",
    "\n",
    "print(\"\\n\", comparison_df.to_string(index=False))\n",
    "\n",
    "# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ (F1 Score ê¸°ì¤€)\n",
    "if multi_cv_f1 > gauss_cv_f1:\n",
    "    print(f\"\\nâœ… MultinomialNBê°€ ë” ìš°ìˆ˜ (CV F1 Score: {multi_cv_f1:.4f})\")\n",
    "    best_model = nb_multi_best\n",
    "    best_model_name = 'MultinomialNB'\n",
    "    best_valid_X = valid_X_multi\n",
    "else:\n",
    "    print(f\"\\nâœ… GaussianNBê°€ ë” ìš°ìˆ˜ (CV F1 Score: {gauss_cv_f1:.4f})\")\n",
    "    best_model = nb_gauss\n",
    "    best_model_name = 'GaussianNB'\n",
    "    best_valid_X = valid_X_gauss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. ë¡œì§€ìŠ¤í‹± íšŒê·€ì™€ ë¹„êµ (ë¬¸ì œì—ì„œ ìš”êµ¬ì‹œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸\n",
    "logreg = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "# MultinomialNBì™€ ê°™ì€ ë°ì´í„°ë¡œ í•™ìŠµ\n",
    "scores_logreg_f1 = cross_val_score(logreg, X_multi, y, cv=5, scoring=scoring)\n",
    "\n",
    "print(f\"ë¡œì§€ìŠ¤í‹± íšŒê·€ 5-Fold CV {metric_name}: {scores_logreg_f1.mean():.4f}\")\n",
    "\n",
    "# ë¹„êµ\n",
    "print(f\"\\n[ëª¨ë¸ ë¹„êµ - {metric_name}]\")\n",
    "print(f\"MultinomialNB: {multi_cv_f1:.4f}\")\n",
    "print(f\"GaussianNB:    {gauss_cv_f1:.4f}\")\n",
    "print(f\"ë¡œì§€ìŠ¤í‹± íšŒê·€:  {scores_logreg_f1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. ìµœì¢… ì„±ê³¼ ë° ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ì§„ ë¶„ë¥˜ì¸ ê²½ìš° ROC AUC ê³„ì‚° ë° ì‹œê°í™”\n",
    "if len(np.unique(y)) == 2:\n",
    "    # MultinomialNB\n",
    "    multi_pred_prob = nb_multi_best.predict_proba(valid_X_multi)[:, 1]\n",
    "    multi_auc = roc_auc_score(valid_y, multi_pred_prob)\n",
    "    fpr_multi, tpr_multi, _ = roc_curve(valid_y, multi_pred_prob)\n",
    "    \n",
    "    # GaussianNB\n",
    "    gauss_pred_prob = nb_gauss.predict_proba(valid_X_gauss)[:, 1]\n",
    "    gauss_auc = roc_auc_score(valid_y, gauss_pred_prob)\n",
    "    fpr_gauss, tpr_gauss, _ = roc_curve(valid_y, gauss_pred_prob)\n",
    "    \n",
    "    # ROC ê³¡ì„ \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr_multi, tpr_multi, color='blue', lw=2, \n",
    "             label=f'MultinomialNB (AUC = {multi_auc:.4f})')\n",
    "    plt.plot(fpr_gauss, tpr_gauss, color='green', lw=2,\n",
    "             label=f'GaussianNB (AUC = {gauss_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('ROC Curve Comparison', fontsize=14)\n",
    "    plt.legend(loc=\"lower right\", fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"MultinomialNB ROC AUC (ê²€ì¦): {multi_auc:.4f}\")\n",
    "    print(f\"GaussianNB ROC AUC (ê²€ì¦): {gauss_auc:.4f}\")\n",
    "else:\n",
    "    print(\"ë‹¤ì¤‘ ë¶„ë¥˜: ROC ê³¡ì„ ì€ ì´ì§„ ë¶„ë¥˜ì—ì„œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\")\n",
    "    print(\"ëŒ€ì‹  Confusion Matrixë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)\n",
    "print(f\"\\n[Confusion Matrix - {best_model_name}]\")\n",
    "cm = confusion_matrix(valid_y, best_model.predict(best_valid_X))\n",
    "print(cm)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)\n",
    "print(f\"\\n[Classification Report - {best_model_name}]\")\n",
    "pred_y = best_model.predict(best_valid_X)\n",
    "print(classification_report(valid_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. ìµœì¢… ê²°ê³¼ ìš”ì•½ âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ğŸ¯ ìµœì¢… ê²°ê³¼ ìš”ì•½ (ê¸°ì¶œ ëŒ€ì‘ ì™„ë£Œ!)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_acc = accuracy_score(valid_y, best_model.predict(best_valid_X))\n",
    "final_f1 = f1_score(valid_y, best_model.predict(best_valid_X), average='weighted' if len(np.unique(y)) > 2 else 'binary')\n",
    "\n",
    "if best_model_name == 'MultinomialNB':\n",
    "    final_cv_acc = multi_cv_acc\n",
    "    final_cv_f1 = multi_cv_f1\n",
    "    print(f\"\"\"\n",
    "âœ… ìµœì¢… ì„ íƒ ëª¨ë¸: MultinomialNB\n",
    "- ìµœì  alpha: {best_alpha}\n",
    "\n",
    "ğŸ“Š ê²€ì¦ ë°ì´í„° ì„±ê³¼:\n",
    "- Accuracy:  {final_acc:.4f}\n",
    "- F1 Score:  {final_f1:.4f}\n",
    "\n",
    "ğŸ“Š 5-Fold CV ì„±ê³¼:\n",
    "- Accuracy:  {final_cv_acc:.4f}\n",
    "- F1 Score:  {final_cv_f1:.4f}\n",
    "\"\"\")\n",
    "else:\n",
    "    final_cv_acc = gauss_cv_acc\n",
    "    final_cv_f1 = gauss_cv_f1\n",
    "    print(f\"\"\"\n",
    "âœ… ìµœì¢… ì„ íƒ ëª¨ë¸: GaussianNB\n",
    "\n",
    "ğŸ“Š ê²€ì¦ ë°ì´í„° ì„±ê³¼:\n",
    "- Accuracy:  {final_acc:.4f}\n",
    "- F1 Score:  {final_f1:.4f}\n",
    "\n",
    "ğŸ“Š 5-Fold CV ì„±ê³¼:\n",
    "- Accuracy:  {final_cv_acc:.4f}\n",
    "- F1 Score:  {final_cv_f1:.4f}\n",
    "\"\"\")\n",
    "\n",
    "if len(np.unique(y)) == 2:\n",
    "    final_auc = roc_auc_score(valid_y, best_model.predict_proba(best_valid_X)[:, 1])\n",
    "    if best_model_name == 'MultinomialNB':\n",
    "        final_cv_auc = multi_cv_auc\n",
    "    else:\n",
    "        final_cv_auc = gauss_cv_auc\n",
    "    print(f\"- Valid ROC AUC: {final_auc:.4f}\")\n",
    "    print(f\"- 5-Fold CV ROC AUC: {final_cv_auc:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ‰ ë¶„ì„ ì™„ë£Œ! ëª¨ë“  ê¸°ì¶œ ìœ í˜• ëŒ€ì‘ ì™„ë£Œ!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
